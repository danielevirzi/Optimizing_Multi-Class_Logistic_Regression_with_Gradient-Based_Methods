{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "seed = 13\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(gpu)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimensions of the input data\n",
    "m = 1000\n",
    "d = 1000\n",
    "\n",
    "# Set the number of labels\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset:\n",
    "    def __init__(self, n_samples=1000, n_features=1000, n_classes=50, seed=13):\n",
    "        \"\"\"\n",
    "        Initialize synthetic dataset generator\n",
    "        \n",
    "        Args:\n",
    "            n_samples:  number of samples\n",
    "            n_features: number of features\n",
    "            n_classes:  number of classes\n",
    "            device:     computation device\n",
    "            seed:       random seed\n",
    "        \"\"\"\n",
    "        self.m = n_samples\n",
    "        self.d = n_features\n",
    "        self.k = n_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Set seed\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        # Generate dataset\n",
    "        self._generate_data()\n",
    "        \n",
    "    def _generate_data(self):\n",
    "        \"\"\"Generate synthetic data\"\"\"\n",
    "        \n",
    "        # Generate random input A\n",
    "        self.A = np.random.randn(self.m, self.d)\n",
    "        #print(f\"A: {self.A}\")\n",
    "        \n",
    "        # Generate random matrix X\n",
    "        self.X = np.random.randn(self.d, self.k)    \n",
    "        #print(f\"X: {self.X}\")\n",
    "        \n",
    "        # Generate random error matrix E\n",
    "        self.E = np.random.randn(self.m, self.k)\n",
    "        #print(f\"E: {self.E}\")\n",
    "                \n",
    "        # Generate class labels\n",
    "        Y = self.A @ self.X + self.E\n",
    "        self.B = np.argmax(Y, axis=1) + 1\n",
    "        #print(f\"B: {self.B}\")\n",
    "        \n",
    "        # Create one-hot encoding matrix H\n",
    "        self.H = pd.get_dummies(self.B).astype(float).values\n",
    "        #print(f\"H: {self.H}\")\n",
    "        \n",
    "        # Create ones vector M\n",
    "        self.M = np.ones((1, self.m))\n",
    "\n",
    "        \n",
    "        # Create ones vector K\n",
    "        self.K = np.ones((self.k, 1))\n",
    "        \n",
    "        # Normalize weights with Xavier initialization\n",
    "        self.X_train = np.random.randn(self.d, self.k) * np.sqrt(1 / self.d)\n",
    "        #print(f\"X_train: {self.X_train}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"Return all dataset components\"\"\"\n",
    "        if self.device != \"cpu\":\n",
    "            self.X_train = torch.tensor(self.X_train, device=self.device)\n",
    "            self.A = torch.tensor(self.A, device=self.device)\n",
    "            self.H = torch.tensor(self.H, device=self.device)\n",
    "            self.M = torch.tensor(self.M, device=self.device)\n",
    "            self.K = torch.tensor(self.K, device=self.device)\n",
    "            self.B = torch.tensor(self.B, device=self.device)\n",
    "        \n",
    "        return self.X_train, self.A, self.H, self.M, self.K, self.B\n",
    "    \n",
    "\n",
    "dataset = SyntheticDataset(n_samples=1000, n_features=1000, n_classes=50, seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gpu, A_gpu, H_gpu, M_gpu, K_gpu, B_gpu = dataset.get_data()\n",
    "X_cpu, A_cpu, H_cpu, M_cpu, K_cpu, B_cpu = X_gpu.cpu().numpy(), A_gpu.cpu().numpy(), H_gpu.cpu().numpy(), M_gpu.cpu().numpy(), K_gpu.cpu().numpy(), B_gpu.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(X_cpu, X_gpu.cpu().numpy())\n",
    "assert np.allclose(A_cpu, A_gpu.cpu().numpy())\n",
    "assert np.allclose(H_cpu, H_gpu.cpu().numpy())\n",
    "assert np.allclose(M_cpu, M_gpu.cpu().numpy())\n",
    "assert np.allclose(K_cpu, K_gpu.cpu().numpy())\n",
    "assert np.allclose(B_cpu, B_gpu.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 4365.026231881989\n"
     ]
    }
   ],
   "source": [
    "def compute_cost_cpu(X, A, H, M, K):\n",
    "\n",
    "    # Compute the exponential of AX\n",
    "    exp_AX = np.exp(A @ X)\n",
    "\n",
    "    # Compute the log of the exponential of AX\n",
    "    log = np.log(exp_AX @ K)\n",
    "\n",
    "    # Compute the diagonal of the matrix product\n",
    "    diag = np.diag((A @ X) @ H.T)[:, np.newaxis]\n",
    "\n",
    "    # Compute the cost\n",
    " \n",
    "    cost = M @ ( - diag + log )\n",
    "\n",
    "    return cost.item()\n",
    "\n",
    "# Compute the gradient of the cost function\n",
    "cost = compute_cost_cpu(X_cpu, A_cpu, H_cpu, M_cpu, K_cpu)\n",
    "\n",
    "# Print the cost\n",
    "\n",
    "print('Cost:', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 4365.02623188199\n"
     ]
    }
   ],
   "source": [
    "def compute_cost_gpu(X, A, H, M, K):\n",
    "    \"\"\"\n",
    "    Compute the vectorized cost function using PyTorch operations.\n",
    "    \n",
    "    Args:\n",
    "        X: Input tensor\n",
    "        A: Matrix A\n",
    "        H: Matrix H \n",
    "        M: Matrix M\n",
    "        K: Ones tensor\n",
    "        \n",
    "    Returns:\n",
    "        Cost value as a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the exponential of AX\n",
    "    exp_AX = torch.exp(A @ X)\n",
    "\n",
    "    # Compute the log of the exponential of AX\n",
    "    log = torch.log(exp_AX @ K)\n",
    "\n",
    "    # Compute the diagonal of the matrix product\n",
    "    diag = torch.diag((A @ X) @ H.T)[:, None]\n",
    "\n",
    "    # Compute the cost\n",
    "    cost = M @ (- diag + log)\n",
    "\n",
    "    return cost.item()\n",
    "\n",
    "# Compute the gradient of the cost function\n",
    "cost = compute_cost_gpu(X_gpu, A_gpu, H_gpu, M_gpu, K_gpu)\n",
    "\n",
    "# Print the cost\n",
    "print('Cost:', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(compute_cost_cpu(X_cpu, A_cpu, H_cpu, M_cpu, K_cpu), compute_cost_gpu(X_gpu, A_gpu, H_gpu, M_gpu, K_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the softmax function using NumPy\n",
    "def softmax(matrix):\n",
    "    # Exponentiate the shift matrix\n",
    "    exps = np.exp(matrix)\n",
    "\n",
    "    # Compute the softmax matrix\n",
    "    softmax_matrix = exps / np.sum(exps, axis=0, keepdims=True)\n",
    "\n",
    "    return softmax_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.019\n"
     ]
    }
   ],
   "source": [
    "# CPU implementation\n",
    "def compute_accuracy_cpu(X, A, B, index_0=True):\n",
    "\n",
    "    # Compute the softmax of the matrix product\n",
    "    Y_pred = softmax(A @ X)\n",
    "\n",
    "    if index_0 == True:\n",
    "        # Get the index of the maximum value in each row\n",
    "        B_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "    else:\n",
    "        # Get the index of the maximum value in each row\n",
    "        B_pred = np.argmax(Y_pred, axis=1) + 1\n",
    "\n",
    "    # Compute the accuracy of the model\n",
    "    accuracy = accuracy_score(B, B_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "accuracy_cpu = compute_accuracy_cpu(X_cpu, A_cpu, B_cpu)\n",
    "\n",
    "print('Accuracy:', accuracy_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.01900000125169754\n"
     ]
    }
   ],
   "source": [
    "# GPU version\n",
    "\n",
    "def accuracy_score_gpu(y_true, y_pred):\n",
    "    \n",
    "    # Compute the accuracy of the model\n",
    "    accuracy = torch.sum(y_true == y_pred).float() / y_true.shape[0]\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_accuracy_gpu(X, A, B, index_0=True):\n",
    "\n",
    "    # Compute the softmax of the matrix product\n",
    "    Y_pred = torch.nn.functional.softmax(A @ X, dim=0)\n",
    "\n",
    "\n",
    "    if index_0 == True:\n",
    "        # Get the index of the maximum value in each row\n",
    "        B_pred = torch.argmax(Y_pred, dim=1)\n",
    "\n",
    "    else:\n",
    "        # Get the index of the maximum value in each row\n",
    "        B_pred = torch.argmax(Y_pred, dim=1) + 1\n",
    "\n",
    "    # Compute the accuracy of the model\n",
    "    \n",
    "    accuracy = accuracy_score_gpu(B, B_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy_gpu = compute_accuracy_gpu(X_gpu, A_gpu, B_gpu)\n",
    "\n",
    "print('Accuracy:', accuracy_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred_cpu: [[3.84566082e-04 7.94674381e-04 8.33944364e-04 ... 8.98158523e-04\n",
      "  1.13071307e-03 1.21832336e-03]\n",
      " [4.53652067e-03 1.13443448e-04 5.67530872e-04 ... 7.01270522e-04\n",
      "  1.55643244e-04 9.88229179e-04]\n",
      " [8.32167947e-04 7.06369024e-04 1.07814387e-03 ... 1.33396681e-03\n",
      "  4.61266396e-04 5.69727853e-04]\n",
      " ...\n",
      " [1.40366164e-03 1.09551287e-03 1.13839201e-04 ... 1.11284975e-03\n",
      "  4.34246758e-04 1.27991847e-03]\n",
      " [8.80852486e-04 4.90402919e-04 5.90929050e-04 ... 1.93253824e-04\n",
      "  4.19979584e-04 2.42557697e-05]\n",
      " [2.49510331e-04 5.66630254e-04 1.41446040e-03 ... 1.20491752e-03\n",
      "  6.87934806e-04 8.77860674e-03]]\n",
      "Y_pred_gpu: tensor([[3.8457e-04, 7.9467e-04, 8.3394e-04,  ..., 8.9816e-04, 1.1307e-03,\n",
      "         1.2183e-03],\n",
      "        [4.5365e-03, 1.1344e-04, 5.6753e-04,  ..., 7.0127e-04, 1.5564e-04,\n",
      "         9.8823e-04],\n",
      "        [8.3217e-04, 7.0637e-04, 1.0781e-03,  ..., 1.3340e-03, 4.6127e-04,\n",
      "         5.6973e-04],\n",
      "        ...,\n",
      "        [1.4037e-03, 1.0955e-03, 1.1384e-04,  ..., 1.1128e-03, 4.3425e-04,\n",
      "         1.2799e-03],\n",
      "        [8.8085e-04, 4.9040e-04, 5.9093e-04,  ..., 1.9325e-04, 4.1998e-04,\n",
      "         2.4256e-05],\n",
      "        [2.4951e-04, 5.6663e-04, 1.4145e-03,  ..., 1.2049e-03, 6.8793e-04,\n",
      "         8.7786e-03]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Y_pred_cpu = softmax(A_cpu @ X_cpu) \n",
    "Y_pred_gpu = torch.nn.functional.softmax(A_gpu @ X_gpu, dim=0)\n",
    "\n",
    "print('Y_pred_cpu:', Y_pred_cpu)\n",
    "print('Y_pred_gpu:', Y_pred_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(compute_accuracy_cpu(X_cpu, A_cpu, B_cpu), compute_accuracy_gpu(X_gpu, A_gpu, B_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient CPU: [[-4.2416887  -1.63765546  4.64962977 ... -3.49680882 -2.98012839\n",
      "   8.27944512]\n",
      " [ 6.89796423 -0.8737726   7.68001854 ... -1.93752301 -3.57376666\n",
      "   5.4840611 ]\n",
      " [ 4.54852217  4.81075999 -5.58602402 ... -9.12775714 -0.47941134\n",
      "  -7.08780965]\n",
      " ...\n",
      " [ 1.54767785 -3.07158962 -0.17057505 ...  2.57090769 -1.78023225\n",
      "  -3.42591692]\n",
      " [-0.5860776  10.4326188  -5.87404158 ... -3.03621608  1.58723474\n",
      "  -1.99958676]\n",
      " [ 3.11195133  3.10083908  6.17721249 ... -0.46954968 -0.92179899\n",
      "   2.17967824]]\n"
     ]
    }
   ],
   "source": [
    "# CPU implementation\n",
    "def gradient_cpu(X, A, H, K):\n",
    "\n",
    "    # Compute the exponential of A @ X\n",
    "    exp_AX = np.exp(A @ X)\n",
    "\n",
    "    # Compute the derivative of the loss function with respect to X\n",
    "    df_dX = - A.T @ (H - (exp_AX * (1 / (exp_AX @ K))))  # Perform broadcasting between exp_AX and (1 / (exp_AX @ I)) instead of compting the C matrix\n",
    "\n",
    "    return df_dX\n",
    "\n",
    "print('Gradient CPU:', gradient_cpu(X_cpu, A_cpu, H_cpu, K_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient GPU: tensor([[-4.2417, -1.6377,  4.6496,  ..., -3.4968, -2.9801,  8.2794],\n",
      "        [ 6.8980, -0.8738,  7.6800,  ..., -1.9375, -3.5738,  5.4841],\n",
      "        [ 4.5485,  4.8108, -5.5860,  ..., -9.1278, -0.4794, -7.0878],\n",
      "        ...,\n",
      "        [ 1.5477, -3.0716, -0.1706,  ...,  2.5709, -1.7802, -3.4259],\n",
      "        [-0.5861, 10.4326, -5.8740,  ..., -3.0362,  1.5872, -1.9996],\n",
      "        [ 3.1120,  3.1008,  6.1772,  ..., -0.4695, -0.9218,  2.1797]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# GPU implementation\n",
    "def gradient_gpu(X, A, H, K):\n",
    "\n",
    "    # Compute the exponential of A @ X\n",
    "    exp_AX = torch.exp(A @ X)\n",
    "\n",
    "    # Compute the derivative of the loss function with respect to X\n",
    "    df_dX = - A.T @ (H - (exp_AX * (1 / (exp_AX @ K))) )\n",
    "\n",
    "    return df_dX\n",
    "\n",
    "print('Gradient GPU:', gradient_gpu(X_gpu, A_gpu, H_gpu, K_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(gradient_cpu(X_cpu, A_cpu, H_cpu, K_cpu), gradient_gpu(X_gpu, A_gpu, H_gpu, K_gpu).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient block CPU: [[-4.24168870e+00]\n",
      " [ 6.89796423e+00]\n",
      " [ 4.54852217e+00]\n",
      " [-4.72179827e+00]\n",
      " [ 5.74557533e+00]\n",
      " [-6.37645183e-01]\n",
      " [-1.51719552e+00]\n",
      " [-1.68197467e+00]\n",
      " [ 3.07561104e+00]\n",
      " [-5.89641317e+00]\n",
      " [-4.90992688e+00]\n",
      " [-6.97861331e+00]\n",
      " [-4.15606610e+00]\n",
      " [-1.14157227e+00]\n",
      " [ 5.80265290e+00]\n",
      " [-1.71761143e+00]\n",
      " [-9.76405732e+00]\n",
      " [-3.40760927e+00]\n",
      " [ 3.84798813e+00]\n",
      " [-5.55835233e+00]\n",
      " [-7.71740571e-01]\n",
      " [ 3.95604572e+00]\n",
      " [-7.13053592e+00]\n",
      " [ 2.46635708e+00]\n",
      " [-7.29412220e+00]\n",
      " [ 4.81021528e-01]\n",
      " [ 9.59652677e+00]\n",
      " [-1.76135463e+00]\n",
      " [-9.46779544e+00]\n",
      " [-1.16278880e+00]\n",
      " [-4.37376767e+00]\n",
      " [ 6.64681129e+00]\n",
      " [ 2.03661627e+00]\n",
      " [ 3.19644528e+00]\n",
      " [-2.10171218e+00]\n",
      " [ 5.85570650e+00]\n",
      " [ 6.49177912e+00]\n",
      " [-3.01719554e+00]\n",
      " [-5.99118032e+00]\n",
      " [-2.56822693e+00]\n",
      " [ 1.24302551e+00]\n",
      " [ 1.23277359e+00]\n",
      " [ 2.12392719e+00]\n",
      " [-2.62376958e+00]\n",
      " [-1.63582712e+00]\n",
      " [ 2.32658849e+00]\n",
      " [ 8.99859287e-01]\n",
      " [-5.84539987e+00]\n",
      " [ 7.66656935e+00]\n",
      " [-1.65423586e+00]\n",
      " [-1.07885926e+01]\n",
      " [ 1.57111255e+01]\n",
      " [-8.25622099e-01]\n",
      " [-5.88658329e+00]\n",
      " [ 5.85652613e+00]\n",
      " [-2.41740542e+00]\n",
      " [-7.19641959e+00]\n",
      " [-7.49962787e-01]\n",
      " [ 5.52108136e+00]\n",
      " [ 3.33447235e+00]\n",
      " [ 2.03443004e+00]\n",
      " [ 3.16057595e+00]\n",
      " [-6.43135240e+00]\n",
      " [-1.20014681e+00]\n",
      " [-1.20494026e+00]\n",
      " [-2.81831663e-01]\n",
      " [ 5.28281354e+00]\n",
      " [ 7.46903812e+00]\n",
      " [-6.12802141e-01]\n",
      " [ 7.77212956e+00]\n",
      " [-5.67068845e+00]\n",
      " [-1.38355842e+00]\n",
      " [-1.47879979e+00]\n",
      " [-3.54523651e+00]\n",
      " [-5.43785070e+00]\n",
      " [-5.56537393e+00]\n",
      " [ 3.45989215e+00]\n",
      " [-2.94060681e+00]\n",
      " [ 2.44534492e+00]\n",
      " [-3.47312141e+00]\n",
      " [ 3.39511227e+00]\n",
      " [-6.44400979e+00]\n",
      " [ 2.71064063e-02]\n",
      " [ 4.55021077e+00]\n",
      " [ 8.38396897e-01]\n",
      " [-5.37498097e+00]\n",
      " [ 2.97128375e+00]\n",
      " [ 3.20226619e+00]\n",
      " [ 6.78541608e+00]\n",
      " [ 7.56172197e+00]\n",
      " [ 2.48166557e+00]\n",
      " [ 1.04307977e+00]\n",
      " [-1.09650775e+00]\n",
      " [ 4.07389595e+00]\n",
      " [-3.87483976e-01]\n",
      " [ 2.69358904e+00]\n",
      " [-8.49659127e-01]\n",
      " [-2.37232286e+00]\n",
      " [ 7.40687498e+00]\n",
      " [ 3.01218687e+00]\n",
      " [ 3.72069863e+00]\n",
      " [ 6.43427859e+00]\n",
      " [-1.00286624e+01]\n",
      " [-4.97856853e+00]\n",
      " [ 3.03222704e+00]\n",
      " [-3.66429665e+00]\n",
      " [ 9.40948226e+00]\n",
      " [ 2.79982859e+00]\n",
      " [-4.11945850e-01]\n",
      " [-5.89650829e+00]\n",
      " [ 1.74645498e+00]\n",
      " [ 8.09608623e-01]\n",
      " [ 4.37104961e+00]\n",
      " [-2.49978181e+00]\n",
      " [ 2.53725006e-01]\n",
      " [ 5.24643731e-01]\n",
      " [ 1.61807932e+00]\n",
      " [ 4.74965879e+00]\n",
      " [-5.22688117e+00]\n",
      " [ 9.29337832e-01]\n",
      " [ 1.69015674e+00]\n",
      " [-5.04416858e+00]\n",
      " [ 6.07492494e+00]\n",
      " [ 3.81242097e+00]\n",
      " [-6.04256825e+00]\n",
      " [-6.17012383e+00]\n",
      " [-4.37436577e+00]\n",
      " [-4.88739835e+00]\n",
      " [ 6.55038708e-01]\n",
      " [-5.58282142e-01]\n",
      " [ 3.90028917e+00]\n",
      " [-2.39456099e+00]\n",
      " [ 7.80499236e-01]\n",
      " [ 4.18991983e+00]\n",
      " [-3.49076475e+00]\n",
      " [ 1.06029535e+01]\n",
      " [ 1.87780044e+00]\n",
      " [-2.54472538e+00]\n",
      " [ 8.47259660e-01]\n",
      " [ 3.22925442e+00]\n",
      " [ 1.26059203e+01]\n",
      " [ 8.70887263e+00]\n",
      " [ 5.09230285e-01]\n",
      " [-9.09008171e+00]\n",
      " [-8.46003841e+00]\n",
      " [-1.66246435e+00]\n",
      " [ 1.18390266e-02]\n",
      " [-6.10902249e+00]\n",
      " [-5.32957295e+00]\n",
      " [-2.01295774e+00]\n",
      " [-7.64931832e+00]\n",
      " [ 3.09029976e+00]\n",
      " [ 3.45009396e+00]\n",
      " [-7.80587242e+00]\n",
      " [-2.01316233e-01]\n",
      " [-7.01138323e+00]\n",
      " [ 3.67990864e+00]\n",
      " [ 1.00595896e+00]\n",
      " [ 5.51128811e+00]\n",
      " [ 3.71166105e+00]\n",
      " [-1.30988109e+01]\n",
      " [-4.74551498e+00]\n",
      " [-2.85971936e-01]\n",
      " [ 1.09457180e+00]\n",
      " [ 1.86567397e+00]\n",
      " [ 9.12395361e-02]\n",
      " [-1.75542304e+00]\n",
      " [-5.57398115e+00]\n",
      " [-1.72985448e+00]\n",
      " [ 5.65883663e+00]\n",
      " [ 4.85777075e+00]\n",
      " [-2.73349420e+00]\n",
      " [-2.34542044e-01]\n",
      " [-3.39896566e+00]\n",
      " [-3.48605028e+00]\n",
      " [ 4.88105344e+00]\n",
      " [ 1.69415133e+00]\n",
      " [ 1.05407278e+01]\n",
      " [ 4.45206224e+00]\n",
      " [ 1.93007552e+00]\n",
      " [-3.45406122e+00]\n",
      " [-2.99771464e+00]\n",
      " [ 9.56670477e+00]\n",
      " [ 3.65584085e+00]\n",
      " [-5.96548633e+00]\n",
      " [ 6.47780588e+00]\n",
      " [-1.06923596e+00]\n",
      " [-2.29427665e+00]\n",
      " [ 2.76700620e+00]\n",
      " [ 8.08549602e-01]\n",
      " [-4.84488161e+00]\n",
      " [ 4.48608435e+00]\n",
      " [-4.61473648e+00]\n",
      " [-1.03152159e+01]\n",
      " [-2.24390072e+00]\n",
      " [ 2.61192401e-01]\n",
      " [-1.03056761e+00]\n",
      " [-2.13835395e+00]\n",
      " [ 4.31452118e+00]\n",
      " [ 7.50371193e+00]\n",
      " [ 7.84254249e+00]\n",
      " [-3.88550697e+00]\n",
      " [ 8.12305938e+00]\n",
      " [-1.32003236e+01]\n",
      " [ 1.04876935e-03]\n",
      " [-6.97870012e+00]\n",
      " [ 3.51050604e+00]\n",
      " [-2.23852887e+00]\n",
      " [-1.00387496e+00]\n",
      " [-2.86914135e+00]\n",
      " [ 4.90872132e+00]\n",
      " [-4.88110381e+00]\n",
      " [-7.31526718e+00]\n",
      " [ 2.84603232e+00]\n",
      " [-1.43190776e+00]\n",
      " [-5.99367827e+00]\n",
      " [-6.14767987e+00]\n",
      " [-1.23704456e+01]\n",
      " [ 6.76917938e+00]\n",
      " [ 6.41567834e+00]\n",
      " [-6.47677725e+00]\n",
      " [ 1.85716165e+00]\n",
      " [ 1.99529474e+00]\n",
      " [ 7.87035123e+00]\n",
      " [-4.94422399e+00]\n",
      " [ 8.74824802e+00]\n",
      " [ 1.77488538e+00]\n",
      " [ 8.60829345e+00]\n",
      " [ 3.98497547e+00]\n",
      " [ 3.26911609e+00]\n",
      " [ 1.26884111e+00]\n",
      " [ 7.52975158e+00]\n",
      " [ 2.12325438e+00]\n",
      " [ 7.44637931e+00]\n",
      " [ 3.93960625e+00]\n",
      " [-6.79242027e+00]\n",
      " [ 8.39498964e-01]\n",
      " [-7.26461626e-01]\n",
      " [ 6.49830452e+00]\n",
      " [-4.27559078e+00]\n",
      " [ 5.67542030e+00]\n",
      " [ 6.37771636e+00]\n",
      " [-2.86631726e+00]\n",
      " [ 7.21768303e+00]\n",
      " [ 9.36295722e-01]\n",
      " [ 6.87823993e+00]\n",
      " [-3.88140672e+00]\n",
      " [-2.92418340e+00]\n",
      " [ 9.23476780e+00]\n",
      " [-8.39201533e+00]\n",
      " [ 2.36152773e+00]\n",
      " [ 4.32815287e+00]\n",
      " [-3.78247627e+00]\n",
      " [ 9.21257410e+00]\n",
      " [-4.50676778e+00]\n",
      " [ 5.17775238e+00]\n",
      " [-3.10290879e+00]\n",
      " [ 4.65371658e+00]\n",
      " [ 2.50701936e-01]\n",
      " [ 6.13584996e+00]\n",
      " [ 1.95912514e+00]\n",
      " [ 5.19636305e-01]\n",
      " [ 4.72065457e+00]\n",
      " [ 4.32862653e+00]\n",
      " [-6.22747075e+00]\n",
      " [-3.33291164e+00]\n",
      " [ 3.09444773e+00]\n",
      " [-7.59867523e+00]\n",
      " [-6.68487245e+00]\n",
      " [ 1.41867566e+01]\n",
      " [ 3.23383569e+00]\n",
      " [-1.13233161e+01]\n",
      " [-6.01494043e+00]\n",
      " [-3.77267551e+00]\n",
      " [ 1.77743784e+00]\n",
      " [-9.41781508e+00]\n",
      " [-1.48320309e+00]\n",
      " [-5.24388383e+00]\n",
      " [-1.05404675e+01]\n",
      " [ 2.48541328e+00]\n",
      " [-4.67176955e+00]\n",
      " [-7.47828971e+00]\n",
      " [ 1.41479076e+00]\n",
      " [ 1.12767783e+01]\n",
      " [ 1.82040786e+00]\n",
      " [-9.16319160e+00]\n",
      " [-5.73140532e+00]\n",
      " [ 1.32488954e-02]\n",
      " [-1.79388090e+00]\n",
      " [-6.77196265e+00]\n",
      " [ 1.20688055e+00]\n",
      " [ 5.86556580e+00]\n",
      " [-1.66212241e+00]\n",
      " [-6.70147657e+00]\n",
      " [ 1.81011588e+01]\n",
      " [-9.01469117e+00]\n",
      " [ 7.25432213e-02]\n",
      " [-3.52862921e+00]\n",
      " [-5.20307505e+00]\n",
      " [-4.15565265e+00]\n",
      " [ 6.31992219e+00]\n",
      " [ 4.94089760e+00]\n",
      " [-4.78286154e+00]\n",
      " [-9.37415512e+00]\n",
      " [-6.81607927e+00]\n",
      " [ 4.61351192e+00]\n",
      " [-4.52376966e+00]\n",
      " [ 3.63974903e+00]\n",
      " [ 4.67701096e+00]\n",
      " [-2.75893750e+00]\n",
      " [ 3.85128407e+00]\n",
      " [ 1.29314012e+01]\n",
      " [-1.04222088e+00]\n",
      " [ 1.25112045e+01]\n",
      " [ 1.72546314e+00]\n",
      " [ 3.74319048e+00]\n",
      " [ 1.62142500e+00]\n",
      " [ 1.17388583e+01]\n",
      " [-9.65024747e-02]\n",
      " [ 1.99160999e+00]\n",
      " [ 6.07985482e-01]\n",
      " [-3.01463100e-01]\n",
      " [ 2.61039060e+00]\n",
      " [-2.42251903e+00]\n",
      " [-9.53605381e+00]\n",
      " [-5.01212131e+00]\n",
      " [ 7.18349628e+00]\n",
      " [-9.15326522e+00]\n",
      " [-5.26306230e+00]\n",
      " [-6.78412782e+00]\n",
      " [ 5.62477692e-01]\n",
      " [ 2.15393974e+00]\n",
      " [ 9.17114893e+00]\n",
      " [-2.63532915e+00]\n",
      " [-4.19951200e+00]\n",
      " [ 8.91990232e-01]\n",
      " [-4.00248573e+00]\n",
      " [ 4.26955572e+00]\n",
      " [ 4.65430983e+00]\n",
      " [-3.49920414e+00]\n",
      " [ 8.94664639e+00]\n",
      " [-1.85674021e+00]\n",
      " [ 5.63244331e+00]\n",
      " [-1.70839400e+00]\n",
      " [ 2.33600649e+00]\n",
      " [ 6.58270358e-01]\n",
      " [ 1.22706384e+01]\n",
      " [-3.68659900e+00]\n",
      " [-7.21942223e+00]\n",
      " [ 6.39082936e+00]\n",
      " [ 5.32113346e+00]\n",
      " [-3.31424148e+00]\n",
      " [ 4.06776547e+00]\n",
      " [ 5.55114060e+00]\n",
      " [-6.79880643e+00]\n",
      " [ 5.05902643e+00]\n",
      " [-4.66360955e+00]\n",
      " [-2.63907915e+00]\n",
      " [ 1.41900536e+00]\n",
      " [ 6.77755408e+00]\n",
      " [-1.66098400e+00]\n",
      " [ 3.89207161e+00]\n",
      " [-3.47486146e+00]\n",
      " [ 5.33520313e+00]\n",
      " [-4.40568529e+00]\n",
      " [-1.53031657e+00]\n",
      " [ 3.17580051e+00]\n",
      " [-9.32237414e+00]\n",
      " [ 4.25321837e+00]\n",
      " [ 1.83782033e+00]\n",
      " [ 3.05314699e+00]\n",
      " [-3.65265758e+00]\n",
      " [-2.45198260e+00]\n",
      " [ 7.89600660e+00]\n",
      " [ 6.28393337e+00]\n",
      " [ 3.85253855e+00]\n",
      " [-3.58414118e+00]\n",
      " [-4.85632553e+00]\n",
      " [-4.85123077e+00]\n",
      " [-2.12620150e+00]\n",
      " [ 5.10125484e+00]\n",
      " [ 3.28008771e-01]\n",
      " [-4.58659515e+00]\n",
      " [ 1.11950443e+00]\n",
      " [-5.22238532e+00]\n",
      " [ 3.62270032e+00]\n",
      " [ 3.52929200e+00]\n",
      " [-5.82230930e+00]\n",
      " [ 1.70782778e+00]\n",
      " [-3.04169480e+00]\n",
      " [-5.72050733e+00]\n",
      " [-2.57603646e+00]\n",
      " [-3.45048646e+00]\n",
      " [ 5.74044933e+00]\n",
      " [-3.26892739e+00]\n",
      " [-5.93896962e+00]\n",
      " [ 2.41079329e+00]\n",
      " [ 8.88427380e+00]\n",
      " [-1.63729587e+00]\n",
      " [-2.40605835e-01]\n",
      " [ 3.10990108e-01]\n",
      " [ 5.47520883e-01]\n",
      " [ 1.27797037e+01]\n",
      " [ 9.66302928e+00]\n",
      " [-9.90572164e+00]\n",
      " [ 9.74460449e-01]\n",
      " [ 4.76925479e+00]\n",
      " [ 3.18055565e+00]\n",
      " [-4.51095988e+00]\n",
      " [ 6.57256473e+00]\n",
      " [-2.40137421e+00]\n",
      " [ 3.54278197e+00]\n",
      " [-7.15495598e+00]\n",
      " [ 7.94207738e+00]\n",
      " [ 6.73301262e+00]\n",
      " [-4.02430037e+00]\n",
      " [-4.37086611e+00]\n",
      " [ 1.37322859e+00]\n",
      " [ 8.12628260e+00]\n",
      " [-4.37431880e+00]\n",
      " [ 5.18156523e+00]\n",
      " [-2.81376119e+00]\n",
      " [-6.90138043e+00]\n",
      " [ 3.01141983e+00]\n",
      " [-1.02448102e+01]\n",
      " [ 3.21037840e+00]\n",
      " [-9.34312886e+00]\n",
      " [-1.27160216e+01]\n",
      " [-1.72822009e+00]\n",
      " [ 8.71723552e+00]\n",
      " [-4.00585424e+00]\n",
      " [ 1.13174991e+00]\n",
      " [-1.60651396e+01]\n",
      " [ 5.65581560e+00]\n",
      " [ 1.00170558e+00]\n",
      " [ 3.00369023e+00]\n",
      " [-9.76087931e-01]\n",
      " [ 6.61604086e+00]\n",
      " [ 1.87176461e+00]\n",
      " [ 7.20572432e+00]\n",
      " [-6.96210071e+00]\n",
      " [-4.22861905e+00]\n",
      " [ 3.06645386e+00]\n",
      " [-2.45840976e+00]\n",
      " [-2.91060840e+00]\n",
      " [-2.23964420e+00]\n",
      " [-1.64872291e+01]\n",
      " [ 1.90204407e+00]\n",
      " [-5.04611944e+00]\n",
      " [-1.61176272e+00]\n",
      " [ 8.28135875e+00]\n",
      " [-6.46168288e+00]\n",
      " [ 8.43473151e+00]\n",
      " [ 5.04334746e+00]\n",
      " [-4.91026805e+00]\n",
      " [-1.06650014e+01]\n",
      " [ 8.94899170e+00]\n",
      " [-5.55213501e+00]\n",
      " [ 1.58020163e+00]\n",
      " [-4.20443919e+00]\n",
      " [-8.19461824e+00]\n",
      " [-2.00132753e+00]\n",
      " [-2.79212025e+00]\n",
      " [-4.35950690e+00]\n",
      " [-6.22387979e+00]\n",
      " [-1.42456383e+00]\n",
      " [ 1.24610461e+01]\n",
      " [ 2.50971228e+00]\n",
      " [ 3.39406666e+00]\n",
      " [-5.50448958e+00]\n",
      " [-8.16326539e+00]\n",
      " [-4.34824433e+00]\n",
      " [ 5.09978937e+00]\n",
      " [ 7.41473896e-01]\n",
      " [-6.59455786e+00]\n",
      " [-2.96393187e+00]\n",
      " [-5.31826917e+00]\n",
      " [ 6.22505361e-01]\n",
      " [ 8.43498227e+00]\n",
      " [ 1.09576161e+01]\n",
      " [-3.62872295e+00]\n",
      " [ 1.04227857e+01]\n",
      " [-3.20553949e+00]\n",
      " [ 4.67203712e+00]\n",
      " [-4.32864726e+00]\n",
      " [-2.68200367e+00]\n",
      " [-3.27532704e+00]\n",
      " [ 4.07156225e+00]\n",
      " [-7.18497564e-01]\n",
      " [-3.59559952e+00]\n",
      " [-2.76970033e+00]\n",
      " [-6.58816992e+00]\n",
      " [ 7.91767805e-01]\n",
      " [-5.49681089e+00]\n",
      " [-3.61847202e+00]\n",
      " [ 5.02278933e+00]\n",
      " [-1.07872620e+00]\n",
      " [ 1.90690816e+00]\n",
      " [ 3.64948685e-01]\n",
      " [-2.62765662e-01]\n",
      " [-7.57598687e+00]\n",
      " [-7.73357965e-02]\n",
      " [ 1.32563543e+01]\n",
      " [ 1.95625322e+00]\n",
      " [-9.48202961e-01]\n",
      " [-3.35639487e+00]\n",
      " [-9.75262341e+00]\n",
      " [-5.74406215e+00]\n",
      " [ 4.92620857e-01]\n",
      " [-3.78726748e+00]\n",
      " [-2.76173407e+00]\n",
      " [ 1.04838313e+00]\n",
      " [-1.83175777e-01]\n",
      " [-1.76470269e+00]\n",
      " [-3.08135877e-01]\n",
      " [-3.31396749e+00]\n",
      " [-2.36705575e-01]\n",
      " [ 4.57016710e-02]\n",
      " [-8.90202908e+00]\n",
      " [-2.45438981e-01]\n",
      " [ 7.33507251e+00]\n",
      " [-9.25334915e+00]\n",
      " [ 8.37177055e-01]\n",
      " [-1.80798257e+01]\n",
      " [ 4.74085571e+00]\n",
      " [-6.81706639e-01]\n",
      " [-5.86942178e+00]\n",
      " [ 1.82771652e-01]\n",
      " [-9.46610853e-02]\n",
      " [ 7.23490742e+00]\n",
      " [-7.60792121e+00]\n",
      " [-8.24635874e+00]\n",
      " [ 1.81789138e+00]\n",
      " [-4.48980975e-01]\n",
      " [-3.78146245e+00]\n",
      " [ 7.85954944e+00]\n",
      " [-2.10919688e+00]\n",
      " [ 5.55001113e+00]\n",
      " [-4.53373290e+00]\n",
      " [ 4.86019610e+00]\n",
      " [ 5.31106093e+00]\n",
      " [ 1.20146979e+01]\n",
      " [ 3.14066124e+00]\n",
      " [-9.25348975e+00]\n",
      " [ 1.98879322e+00]\n",
      " [ 2.62682368e+00]\n",
      " [ 7.84172594e+00]\n",
      " [ 1.56830085e+00]\n",
      " [-4.33487987e+00]\n",
      " [-8.02058202e-01]\n",
      " [-3.66980637e+00]\n",
      " [ 4.18981013e+00]\n",
      " [ 1.00895930e+01]\n",
      " [ 1.29010020e+01]\n",
      " [-8.33923306e+00]\n",
      " [-7.46016438e+00]\n",
      " [-1.03614730e+01]\n",
      " [ 4.36012788e+00]\n",
      " [ 4.15036161e+00]\n",
      " [ 2.50576679e+00]\n",
      " [-2.34722284e+00]\n",
      " [ 6.10667259e+00]\n",
      " [ 5.49916199e+00]\n",
      " [ 8.05878349e+00]\n",
      " [-2.00641774e+00]\n",
      " [ 2.20893796e-02]\n",
      " [ 4.86776918e+00]\n",
      " [ 7.01288874e+00]\n",
      " [-2.19809746e+00]\n",
      " [-2.59276678e+00]\n",
      " [ 1.52997038e+00]\n",
      " [ 1.10251750e-01]\n",
      " [-3.49896545e+00]\n",
      " [ 4.25601594e+00]\n",
      " [ 3.28570755e+00]\n",
      " [ 1.21816539e+01]\n",
      " [ 9.19086261e-01]\n",
      " [ 3.22288620e+00]\n",
      " [-1.11823774e+01]\n",
      " [ 4.10206258e-01]\n",
      " [-1.17687100e+01]\n",
      " [ 2.53481378e+00]\n",
      " [-8.43566943e-01]\n",
      " [ 5.45335676e+00]\n",
      " [ 7.76266996e+00]\n",
      " [ 1.82220566e+00]\n",
      " [ 5.25986938e+00]\n",
      " [-5.02521829e+00]\n",
      " [ 3.34995656e+00]\n",
      " [ 7.31247169e+00]\n",
      " [ 3.64113282e-01]\n",
      " [-5.03544469e+00]\n",
      " [ 5.57029742e-01]\n",
      " [-2.63420597e+00]\n",
      " [-1.00403718e+00]\n",
      " [-5.27123221e+00]\n",
      " [ 6.85966526e+00]\n",
      " [-1.64578210e+00]\n",
      " [-1.56930559e+00]\n",
      " [-1.19071385e-01]\n",
      " [-7.86694753e+00]\n",
      " [-3.87963207e+00]\n",
      " [-1.31422904e+00]\n",
      " [-4.98867039e+00]\n",
      " [-3.17175592e+00]\n",
      " [-1.09927533e+01]\n",
      " [ 1.99789296e+00]\n",
      " [ 1.79412645e+00]\n",
      " [ 5.80104219e+00]\n",
      " [-7.54338048e-01]\n",
      " [-3.83615115e-01]\n",
      " [ 1.27025937e+00]\n",
      " [-2.02426085e+00]\n",
      " [-2.24967467e+00]\n",
      " [-3.58067508e+00]\n",
      " [ 7.68364743e+00]\n",
      " [ 5.00124729e+00]\n",
      " [ 1.95069123e+00]\n",
      " [-3.23402410e-01]\n",
      " [ 3.99286335e+00]\n",
      " [ 9.12268052e-02]\n",
      " [ 5.58154007e+00]\n",
      " [ 8.80576834e+00]\n",
      " [-4.02236557e+00]\n",
      " [ 2.37585398e+00]\n",
      " [ 2.95544603e+00]\n",
      " [-6.30416039e+00]\n",
      " [-2.09481305e+00]\n",
      " [-2.84077652e+00]\n",
      " [-8.76904792e+00]\n",
      " [-2.93918646e+00]\n",
      " [-1.35484379e+00]\n",
      " [-3.12627290e+00]\n",
      " [ 5.10210207e+00]\n",
      " [ 2.23976756e+00]\n",
      " [-1.05048823e+00]\n",
      " [-5.25751319e+00]\n",
      " [ 1.58258262e+00]\n",
      " [ 4.13753993e+00]\n",
      " [-2.87548947e+00]\n",
      " [-4.18698584e+00]\n",
      " [-2.62545489e+00]\n",
      " [ 3.57897102e+00]\n",
      " [-5.91502681e-01]\n",
      " [ 8.82520426e+00]\n",
      " [-6.89740000e+00]\n",
      " [-5.99995106e+00]\n",
      " [-1.72603833e+00]\n",
      " [ 7.33779834e+00]\n",
      " [-1.91264072e+00]\n",
      " [-1.30939481e+01]\n",
      " [ 2.55394347e+00]\n",
      " [-1.04413325e+01]\n",
      " [ 3.13098927e+00]\n",
      " [ 1.62252828e+00]\n",
      " [-1.07874082e+01]\n",
      " [-8.10001731e+00]\n",
      " [ 4.90290516e+00]\n",
      " [-4.80621454e+00]\n",
      " [ 9.64303006e+00]\n",
      " [ 2.26043588e+00]\n",
      " [ 1.71313781e+01]\n",
      " [-3.07524796e-01]\n",
      " [-5.39027206e+00]\n",
      " [ 3.46477981e+00]\n",
      " [ 1.50120011e+01]\n",
      " [ 1.04520662e+01]\n",
      " [ 4.06654500e+00]\n",
      " [-1.19622046e+00]\n",
      " [ 4.25676500e+00]\n",
      " [ 4.72492040e+00]\n",
      " [ 7.89777586e-01]\n",
      " [-4.85906192e+00]\n",
      " [-3.62920186e+00]\n",
      " [ 2.54682487e+00]\n",
      " [-1.02719201e+00]\n",
      " [ 2.56973092e+00]\n",
      " [ 3.32079059e+00]\n",
      " [ 1.23860884e+00]\n",
      " [ 6.35045629e+00]\n",
      " [ 5.77322183e-01]\n",
      " [-1.31810074e+00]\n",
      " [ 2.61225663e+00]\n",
      " [ 3.10180129e+00]\n",
      " [-1.29564053e+01]\n",
      " [-3.61342243e-01]\n",
      " [-1.75142700e+00]\n",
      " [-3.81451160e+00]\n",
      " [ 7.42922782e+00]\n",
      " [-2.08662270e+00]\n",
      " [ 2.41238045e+00]\n",
      " [-1.07862598e+00]\n",
      " [-2.42561570e+00]\n",
      " [-4.95004851e+00]\n",
      " [-9.40784774e+00]\n",
      " [ 8.16254934e+00]\n",
      " [-3.87506832e-01]\n",
      " [ 1.70727115e+01]\n",
      " [-4.85600516e+00]\n",
      " [ 2.28407926e+00]\n",
      " [-3.47415444e+00]\n",
      " [-2.62870984e+00]\n",
      " [-1.03793565e+01]\n",
      " [-9.95060619e+00]\n",
      " [-4.66257058e+00]\n",
      " [ 6.69560341e-02]\n",
      " [-2.14063857e+00]\n",
      " [-9.20010789e+00]\n",
      " [ 5.80660089e+00]\n",
      " [ 7.69956567e+00]\n",
      " [ 2.93863281e+00]\n",
      " [-3.03190181e+00]\n",
      " [-1.03354930e+01]\n",
      " [-2.88578401e+00]\n",
      " [ 8.37059564e+00]\n",
      " [ 2.09505987e-01]\n",
      " [ 1.04578959e+01]\n",
      " [ 4.01668980e-01]\n",
      " [ 2.12631476e+00]\n",
      " [-2.73347808e+00]\n",
      " [ 5.46528347e+00]\n",
      " [ 1.42368416e+00]\n",
      " [ 8.84415064e-01]\n",
      " [-8.42827905e+00]\n",
      " [-8.74476485e+00]\n",
      " [ 6.47649975e-01]\n",
      " [-3.22358137e+00]\n",
      " [ 5.53650037e+00]\n",
      " [-3.36103030e+00]\n",
      " [ 1.30823662e+00]\n",
      " [-1.27654368e+01]\n",
      " [-4.24841101e-02]\n",
      " [ 4.64027048e+00]\n",
      " [ 7.52802806e+00]\n",
      " [ 7.89300547e+00]\n",
      " [ 8.28927677e+00]\n",
      " [-9.86325633e-01]\n",
      " [-8.69046999e+00]\n",
      " [-1.48305135e+00]\n",
      " [ 2.44895215e+00]\n",
      " [ 9.91949187e-01]\n",
      " [ 9.23791784e+00]\n",
      " [ 2.08342087e+00]\n",
      " [ 8.74231661e+00]\n",
      " [-6.55761041e+00]\n",
      " [ 3.69624549e+00]\n",
      " [ 5.27455065e+00]\n",
      " [-8.21397600e+00]\n",
      " [-6.87816201e+00]\n",
      " [ 1.72365966e+00]\n",
      " [-5.73059564e+00]\n",
      " [-2.47442233e+00]\n",
      " [-1.35652771e+00]\n",
      " [-6.49746226e+00]\n",
      " [ 6.35796497e+00]\n",
      " [-1.20354826e+01]\n",
      " [-1.31421537e+01]\n",
      " [-4.78640455e+00]\n",
      " [-6.55244278e+00]\n",
      " [ 2.30524676e+00]\n",
      " [ 2.41314398e+00]\n",
      " [-1.22138462e+00]\n",
      " [-5.54695928e+00]\n",
      " [ 1.09622681e+00]\n",
      " [ 9.73490762e+00]\n",
      " [ 6.17187127e+00]\n",
      " [-1.80031572e+00]\n",
      " [ 1.10443330e+01]\n",
      " [ 3.59665985e+00]\n",
      " [-3.53811178e+00]\n",
      " [ 2.96157372e+00]\n",
      " [ 4.64425258e+00]\n",
      " [-9.01459353e+00]\n",
      " [-1.47343056e+00]\n",
      " [ 3.62349142e+00]\n",
      " [ 8.45604884e+00]\n",
      " [ 2.80792204e+00]\n",
      " [-5.73519383e+00]\n",
      " [-6.11231729e+00]\n",
      " [ 3.54993354e+00]\n",
      " [-5.64738077e-01]\n",
      " [ 3.13545833e+00]\n",
      " [-5.85800147e+00]\n",
      " [ 6.76138572e-01]\n",
      " [-1.60191427e+00]\n",
      " [-9.87632750e+00]\n",
      " [-3.42506818e+00]\n",
      " [ 1.14590473e+01]\n",
      " [-4.19833294e+00]\n",
      " [-3.37739023e-01]\n",
      " [ 6.81790208e-02]\n",
      " [ 4.27048554e+00]\n",
      " [-3.53381709e+00]\n",
      " [-3.06113723e+00]\n",
      " [-7.78889732e+00]\n",
      " [-1.54839660e+00]\n",
      " [ 5.03193700e+00]\n",
      " [ 9.57212772e+00]\n",
      " [ 4.55362178e+00]\n",
      " [-5.65839900e+00]\n",
      " [-2.60926130e+00]\n",
      " [ 9.53654952e+00]\n",
      " [ 7.14019255e+00]\n",
      " [-1.19021305e+00]\n",
      " [ 4.16298820e+00]\n",
      " [ 7.87999449e+00]\n",
      " [ 1.57223666e+00]\n",
      " [ 7.98724814e+00]\n",
      " [-4.29257925e+00]\n",
      " [-4.11984977e+00]\n",
      " [-4.37948506e+00]\n",
      " [ 8.56929724e-01]\n",
      " [-2.22520885e+00]\n",
      " [ 2.19443014e+00]\n",
      " [ 1.32176603e+01]\n",
      " [-4.09286527e-01]\n",
      " [-3.26516303e-01]\n",
      " [ 3.17749543e+00]\n",
      " [ 6.14963390e+00]\n",
      " [-2.34213246e-01]\n",
      " [-5.02919484e+00]\n",
      " [ 2.30123983e+00]\n",
      " [-1.90551817e+00]\n",
      " [ 3.73064674e+00]\n",
      " [ 2.18881161e-01]\n",
      " [ 3.10816183e+00]\n",
      " [ 5.58967711e+00]\n",
      " [ 3.65884195e+00]\n",
      " [ 5.48833149e+00]\n",
      " [-8.28668923e+00]\n",
      " [ 2.73590751e+00]\n",
      " [ 2.83485475e+00]\n",
      " [ 8.85851537e+00]\n",
      " [-5.69401855e+00]\n",
      " [ 3.47728415e+00]\n",
      " [-1.96628845e+00]\n",
      " [-1.89864461e+00]\n",
      " [-2.93896677e+00]\n",
      " [ 1.14537522e+01]\n",
      " [ 1.69425118e+01]\n",
      " [ 4.77303306e+00]\n",
      " [ 1.40472796e+01]\n",
      " [-6.04583640e+00]\n",
      " [-8.11444882e+00]\n",
      " [ 1.06989132e+00]\n",
      " [ 1.78643102e+00]\n",
      " [-6.07879970e+00]\n",
      " [ 1.88481371e-01]\n",
      " [-7.55893659e+00]\n",
      " [ 2.94959085e+00]\n",
      " [ 9.87977753e-02]\n",
      " [-6.45314145e+00]\n",
      " [-4.90819792e+00]\n",
      " [-3.67005238e+00]\n",
      " [-2.86239922e+00]\n",
      " [ 8.54823496e+00]\n",
      " [-7.12667620e+00]\n",
      " [ 6.02851952e+00]\n",
      " [-6.41734131e+00]\n",
      " [ 3.11796703e+00]\n",
      " [ 9.43806582e+00]\n",
      " [-4.45288961e+00]\n",
      " [ 4.04532269e+00]\n",
      " [ 1.37390267e+01]\n",
      " [-1.06584515e+01]\n",
      " [ 3.35868515e+00]\n",
      " [ 4.10787402e+00]\n",
      " [ 6.89723574e+00]\n",
      " [ 3.44535689e+00]\n",
      " [ 3.96311885e+00]\n",
      " [-5.56787863e+00]\n",
      " [-5.35115154e+00]\n",
      " [ 6.95055385e+00]\n",
      " [-7.44676303e+00]\n",
      " [ 9.33993181e+00]\n",
      " [-1.24853996e+01]\n",
      " [-1.50076722e+00]\n",
      " [ 4.64143101e+00]\n",
      " [ 7.57953855e+00]\n",
      " [-4.27584851e+00]\n",
      " [ 5.77116204e+00]\n",
      " [ 1.85540656e+00]\n",
      " [ 1.01250156e+01]\n",
      " [ 6.86280229e+00]\n",
      " [-3.39505722e+00]\n",
      " [ 1.52776202e-01]\n",
      " [ 5.88364235e-01]\n",
      " [-4.15288692e+00]\n",
      " [-6.90263969e+00]\n",
      " [-4.00111595e+00]\n",
      " [ 5.03137917e+00]\n",
      " [ 3.34540490e+00]\n",
      " [-4.15277316e+00]\n",
      " [ 5.66177105e+00]\n",
      " [ 7.07280939e+00]\n",
      " [-2.78704402e+00]\n",
      " [-4.60210887e+00]\n",
      " [ 8.62854323e+00]\n",
      " [ 2.09349897e+00]\n",
      " [ 2.95394639e+00]\n",
      " [ 4.78629852e-01]\n",
      " [ 8.28809754e+00]\n",
      " [ 1.40115770e+00]\n",
      " [ 4.56115357e-01]\n",
      " [-1.15228415e+01]\n",
      " [ 1.69656797e+00]\n",
      " [ 3.10556934e+00]\n",
      " [-7.88987758e+00]\n",
      " [ 3.91231027e+00]\n",
      " [-2.17904208e+00]\n",
      " [-5.66088453e+00]\n",
      " [-5.29246309e+00]\n",
      " [ 2.34213107e+00]\n",
      " [-1.68300536e+00]\n",
      " [-3.71881569e+00]\n",
      " [-1.96465849e-01]\n",
      " [ 3.76907479e+00]\n",
      " [-3.76070467e+00]\n",
      " [-7.95316397e+00]\n",
      " [-1.18286500e+01]\n",
      " [-2.48462719e+00]\n",
      " [-1.11249450e+01]\n",
      " [-6.20608891e+00]\n",
      " [ 6.45883776e+00]\n",
      " [ 2.84408764e+00]\n",
      " [-4.38034730e+00]\n",
      " [ 8.15197124e+00]\n",
      " [-5.60212724e+00]\n",
      " [ 1.85041320e+00]\n",
      " [-2.82059362e+00]\n",
      " [-1.37858350e+00]\n",
      " [-7.63695806e+00]\n",
      " [ 1.17887625e+01]\n",
      " [-9.59547836e+00]\n",
      " [-1.36583256e+00]\n",
      " [ 2.03810710e+00]\n",
      " [ 1.43663260e+00]\n",
      " [-3.75152216e+00]\n",
      " [-1.29212525e+01]\n",
      " [-9.56370568e+00]\n",
      " [-2.24516919e+00]\n",
      " [ 1.37396235e+00]\n",
      " [-9.85119095e+00]\n",
      " [-5.43820194e+00]\n",
      " [ 7.39593709e+00]\n",
      " [-2.40612766e+00]\n",
      " [-1.12606015e+01]\n",
      " [-6.72732457e+00]\n",
      " [ 2.40950370e-01]\n",
      " [-6.58205577e+00]\n",
      " [-1.74565244e-01]\n",
      " [ 5.79479624e+00]\n",
      " [-1.35205099e+00]\n",
      " [ 5.87040316e+00]\n",
      " [-2.32687004e+00]\n",
      " [ 6.37758898e+00]\n",
      " [-1.23113505e+00]\n",
      " [ 8.43539200e+00]\n",
      " [-1.04805605e+00]\n",
      " [-4.45152135e+00]\n",
      " [ 7.52929875e+00]\n",
      " [ 6.59351327e+00]\n",
      " [-3.53088828e+00]\n",
      " [ 9.09303505e+00]\n",
      " [-7.41987587e+00]\n",
      " [ 1.54210744e+00]\n",
      " [ 7.68178793e+00]\n",
      " [-1.02623879e+01]\n",
      " [-1.03104105e+01]\n",
      " [-2.17138898e+00]\n",
      " [-8.62815621e+00]\n",
      " [-6.27208233e+00]\n",
      " [-9.31794438e-01]\n",
      " [ 3.45933022e+00]\n",
      " [-1.30888757e+01]\n",
      " [-9.55076234e-01]\n",
      " [ 1.23104838e+01]\n",
      " [ 5.20396536e-01]\n",
      " [ 2.29618759e+00]\n",
      " [ 8.29489380e+00]\n",
      " [ 5.03205815e+00]\n",
      " [ 5.64993495e+00]\n",
      " [-1.71207819e+00]\n",
      " [-4.47735494e+00]\n",
      " [-4.95225801e+00]\n",
      " [-2.64928482e+00]\n",
      " [-7.13590411e+00]\n",
      " [-4.42075833e+00]\n",
      " [ 9.68045770e+00]\n",
      " [ 3.50149899e+00]\n",
      " [ 8.79548965e+00]\n",
      " [ 6.80063192e+00]\n",
      " [-4.54694634e+00]\n",
      " [ 4.02224227e+00]\n",
      " [ 2.32303727e+00]\n",
      " [ 5.53624541e+00]\n",
      " [ 2.59655545e+00]\n",
      " [ 1.54767785e+00]\n",
      " [-5.86077603e-01]\n",
      " [ 3.11195133e+00]]\n"
     ]
    }
   ],
   "source": [
    "# CPU implementation\n",
    "def gradient_block_cpu(X, A, H, K, index):\n",
    "\n",
    "        # Select the index-th column of X\n",
    "        X_c = X[:, index:index+1]\n",
    "\n",
    "        # Compute the exponential of A @ X\n",
    "        exp_AX = np.exp(A @ X)\n",
    "\n",
    "        # Compute the exponential of A @ X for the index-th column\n",
    "        exp_AX_c = np.exp(A @ X_c)\n",
    "\n",
    "        # Select the index-th column of the one-hot matrix\n",
    "        H_c = H[:, index:index+1]\n",
    "\n",
    "        # Compute the derivative of the loss function with respect to X\n",
    "        df_dX_c = - A.T @ (H_c - (exp_AX_c * (1 / (exp_AX @ K))))  # Perform broadcasting between exp_AX and (1 / (exp_AX @ I))\n",
    "\n",
    "        return df_dX_c\n",
    "\n",
    "print('Gradient block CPU:', gradient_block_cpu(X_cpu, A_cpu, H_cpu, K_cpu, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient block GPU: tensor([[-4.2417e+00],\n",
      "        [ 6.8980e+00],\n",
      "        [ 4.5485e+00],\n",
      "        [-4.7218e+00],\n",
      "        [ 5.7456e+00],\n",
      "        [-6.3765e-01],\n",
      "        [-1.5172e+00],\n",
      "        [-1.6820e+00],\n",
      "        [ 3.0756e+00],\n",
      "        [-5.8964e+00],\n",
      "        [-4.9099e+00],\n",
      "        [-6.9786e+00],\n",
      "        [-4.1561e+00],\n",
      "        [-1.1416e+00],\n",
      "        [ 5.8027e+00],\n",
      "        [-1.7176e+00],\n",
      "        [-9.7641e+00],\n",
      "        [-3.4076e+00],\n",
      "        [ 3.8480e+00],\n",
      "        [-5.5584e+00],\n",
      "        [-7.7174e-01],\n",
      "        [ 3.9560e+00],\n",
      "        [-7.1305e+00],\n",
      "        [ 2.4664e+00],\n",
      "        [-7.2941e+00],\n",
      "        [ 4.8102e-01],\n",
      "        [ 9.5965e+00],\n",
      "        [-1.7614e+00],\n",
      "        [-9.4678e+00],\n",
      "        [-1.1628e+00],\n",
      "        [-4.3738e+00],\n",
      "        [ 6.6468e+00],\n",
      "        [ 2.0366e+00],\n",
      "        [ 3.1964e+00],\n",
      "        [-2.1017e+00],\n",
      "        [ 5.8557e+00],\n",
      "        [ 6.4918e+00],\n",
      "        [-3.0172e+00],\n",
      "        [-5.9912e+00],\n",
      "        [-2.5682e+00],\n",
      "        [ 1.2430e+00],\n",
      "        [ 1.2328e+00],\n",
      "        [ 2.1239e+00],\n",
      "        [-2.6238e+00],\n",
      "        [-1.6358e+00],\n",
      "        [ 2.3266e+00],\n",
      "        [ 8.9986e-01],\n",
      "        [-5.8454e+00],\n",
      "        [ 7.6666e+00],\n",
      "        [-1.6542e+00],\n",
      "        [-1.0789e+01],\n",
      "        [ 1.5711e+01],\n",
      "        [-8.2562e-01],\n",
      "        [-5.8866e+00],\n",
      "        [ 5.8565e+00],\n",
      "        [-2.4174e+00],\n",
      "        [-7.1964e+00],\n",
      "        [-7.4996e-01],\n",
      "        [ 5.5211e+00],\n",
      "        [ 3.3345e+00],\n",
      "        [ 2.0344e+00],\n",
      "        [ 3.1606e+00],\n",
      "        [-6.4314e+00],\n",
      "        [-1.2001e+00],\n",
      "        [-1.2049e+00],\n",
      "        [-2.8183e-01],\n",
      "        [ 5.2828e+00],\n",
      "        [ 7.4690e+00],\n",
      "        [-6.1280e-01],\n",
      "        [ 7.7721e+00],\n",
      "        [-5.6707e+00],\n",
      "        [-1.3836e+00],\n",
      "        [-1.4788e+00],\n",
      "        [-3.5452e+00],\n",
      "        [-5.4379e+00],\n",
      "        [-5.5654e+00],\n",
      "        [ 3.4599e+00],\n",
      "        [-2.9406e+00],\n",
      "        [ 2.4453e+00],\n",
      "        [-3.4731e+00],\n",
      "        [ 3.3951e+00],\n",
      "        [-6.4440e+00],\n",
      "        [ 2.7106e-02],\n",
      "        [ 4.5502e+00],\n",
      "        [ 8.3840e-01],\n",
      "        [-5.3750e+00],\n",
      "        [ 2.9713e+00],\n",
      "        [ 3.2023e+00],\n",
      "        [ 6.7854e+00],\n",
      "        [ 7.5617e+00],\n",
      "        [ 2.4817e+00],\n",
      "        [ 1.0431e+00],\n",
      "        [-1.0965e+00],\n",
      "        [ 4.0739e+00],\n",
      "        [-3.8748e-01],\n",
      "        [ 2.6936e+00],\n",
      "        [-8.4966e-01],\n",
      "        [-2.3723e+00],\n",
      "        [ 7.4069e+00],\n",
      "        [ 3.0122e+00],\n",
      "        [ 3.7207e+00],\n",
      "        [ 6.4343e+00],\n",
      "        [-1.0029e+01],\n",
      "        [-4.9786e+00],\n",
      "        [ 3.0322e+00],\n",
      "        [-3.6643e+00],\n",
      "        [ 9.4095e+00],\n",
      "        [ 2.7998e+00],\n",
      "        [-4.1195e-01],\n",
      "        [-5.8965e+00],\n",
      "        [ 1.7465e+00],\n",
      "        [ 8.0961e-01],\n",
      "        [ 4.3710e+00],\n",
      "        [-2.4998e+00],\n",
      "        [ 2.5373e-01],\n",
      "        [ 5.2464e-01],\n",
      "        [ 1.6181e+00],\n",
      "        [ 4.7497e+00],\n",
      "        [-5.2269e+00],\n",
      "        [ 9.2934e-01],\n",
      "        [ 1.6902e+00],\n",
      "        [-5.0442e+00],\n",
      "        [ 6.0749e+00],\n",
      "        [ 3.8124e+00],\n",
      "        [-6.0426e+00],\n",
      "        [-6.1701e+00],\n",
      "        [-4.3744e+00],\n",
      "        [-4.8874e+00],\n",
      "        [ 6.5504e-01],\n",
      "        [-5.5828e-01],\n",
      "        [ 3.9003e+00],\n",
      "        [-2.3946e+00],\n",
      "        [ 7.8050e-01],\n",
      "        [ 4.1899e+00],\n",
      "        [-3.4908e+00],\n",
      "        [ 1.0603e+01],\n",
      "        [ 1.8778e+00],\n",
      "        [-2.5447e+00],\n",
      "        [ 8.4726e-01],\n",
      "        [ 3.2293e+00],\n",
      "        [ 1.2606e+01],\n",
      "        [ 8.7089e+00],\n",
      "        [ 5.0923e-01],\n",
      "        [-9.0901e+00],\n",
      "        [-8.4600e+00],\n",
      "        [-1.6625e+00],\n",
      "        [ 1.1839e-02],\n",
      "        [-6.1090e+00],\n",
      "        [-5.3296e+00],\n",
      "        [-2.0130e+00],\n",
      "        [-7.6493e+00],\n",
      "        [ 3.0903e+00],\n",
      "        [ 3.4501e+00],\n",
      "        [-7.8059e+00],\n",
      "        [-2.0132e-01],\n",
      "        [-7.0114e+00],\n",
      "        [ 3.6799e+00],\n",
      "        [ 1.0060e+00],\n",
      "        [ 5.5113e+00],\n",
      "        [ 3.7117e+00],\n",
      "        [-1.3099e+01],\n",
      "        [-4.7455e+00],\n",
      "        [-2.8597e-01],\n",
      "        [ 1.0946e+00],\n",
      "        [ 1.8657e+00],\n",
      "        [ 9.1240e-02],\n",
      "        [-1.7554e+00],\n",
      "        [-5.5740e+00],\n",
      "        [-1.7299e+00],\n",
      "        [ 5.6588e+00],\n",
      "        [ 4.8578e+00],\n",
      "        [-2.7335e+00],\n",
      "        [-2.3454e-01],\n",
      "        [-3.3990e+00],\n",
      "        [-3.4861e+00],\n",
      "        [ 4.8811e+00],\n",
      "        [ 1.6942e+00],\n",
      "        [ 1.0541e+01],\n",
      "        [ 4.4521e+00],\n",
      "        [ 1.9301e+00],\n",
      "        [-3.4541e+00],\n",
      "        [-2.9977e+00],\n",
      "        [ 9.5667e+00],\n",
      "        [ 3.6558e+00],\n",
      "        [-5.9655e+00],\n",
      "        [ 6.4778e+00],\n",
      "        [-1.0692e+00],\n",
      "        [-2.2943e+00],\n",
      "        [ 2.7670e+00],\n",
      "        [ 8.0855e-01],\n",
      "        [-4.8449e+00],\n",
      "        [ 4.4861e+00],\n",
      "        [-4.6147e+00],\n",
      "        [-1.0315e+01],\n",
      "        [-2.2439e+00],\n",
      "        [ 2.6119e-01],\n",
      "        [-1.0306e+00],\n",
      "        [-2.1384e+00],\n",
      "        [ 4.3145e+00],\n",
      "        [ 7.5037e+00],\n",
      "        [ 7.8425e+00],\n",
      "        [-3.8855e+00],\n",
      "        [ 8.1231e+00],\n",
      "        [-1.3200e+01],\n",
      "        [ 1.0488e-03],\n",
      "        [-6.9787e+00],\n",
      "        [ 3.5105e+00],\n",
      "        [-2.2385e+00],\n",
      "        [-1.0039e+00],\n",
      "        [-2.8691e+00],\n",
      "        [ 4.9087e+00],\n",
      "        [-4.8811e+00],\n",
      "        [-7.3153e+00],\n",
      "        [ 2.8460e+00],\n",
      "        [-1.4319e+00],\n",
      "        [-5.9937e+00],\n",
      "        [-6.1477e+00],\n",
      "        [-1.2370e+01],\n",
      "        [ 6.7692e+00],\n",
      "        [ 6.4157e+00],\n",
      "        [-6.4768e+00],\n",
      "        [ 1.8572e+00],\n",
      "        [ 1.9953e+00],\n",
      "        [ 7.8704e+00],\n",
      "        [-4.9442e+00],\n",
      "        [ 8.7482e+00],\n",
      "        [ 1.7749e+00],\n",
      "        [ 8.6083e+00],\n",
      "        [ 3.9850e+00],\n",
      "        [ 3.2691e+00],\n",
      "        [ 1.2688e+00],\n",
      "        [ 7.5298e+00],\n",
      "        [ 2.1233e+00],\n",
      "        [ 7.4464e+00],\n",
      "        [ 3.9396e+00],\n",
      "        [-6.7924e+00],\n",
      "        [ 8.3950e-01],\n",
      "        [-7.2646e-01],\n",
      "        [ 6.4983e+00],\n",
      "        [-4.2756e+00],\n",
      "        [ 5.6754e+00],\n",
      "        [ 6.3777e+00],\n",
      "        [-2.8663e+00],\n",
      "        [ 7.2177e+00],\n",
      "        [ 9.3630e-01],\n",
      "        [ 6.8782e+00],\n",
      "        [-3.8814e+00],\n",
      "        [-2.9242e+00],\n",
      "        [ 9.2348e+00],\n",
      "        [-8.3920e+00],\n",
      "        [ 2.3615e+00],\n",
      "        [ 4.3282e+00],\n",
      "        [-3.7825e+00],\n",
      "        [ 9.2126e+00],\n",
      "        [-4.5068e+00],\n",
      "        [ 5.1778e+00],\n",
      "        [-3.1029e+00],\n",
      "        [ 4.6537e+00],\n",
      "        [ 2.5070e-01],\n",
      "        [ 6.1358e+00],\n",
      "        [ 1.9591e+00],\n",
      "        [ 5.1964e-01],\n",
      "        [ 4.7207e+00],\n",
      "        [ 4.3286e+00],\n",
      "        [-6.2275e+00],\n",
      "        [-3.3329e+00],\n",
      "        [ 3.0944e+00],\n",
      "        [-7.5987e+00],\n",
      "        [-6.6849e+00],\n",
      "        [ 1.4187e+01],\n",
      "        [ 3.2338e+00],\n",
      "        [-1.1323e+01],\n",
      "        [-6.0149e+00],\n",
      "        [-3.7727e+00],\n",
      "        [ 1.7774e+00],\n",
      "        [-9.4178e+00],\n",
      "        [-1.4832e+00],\n",
      "        [-5.2439e+00],\n",
      "        [-1.0540e+01],\n",
      "        [ 2.4854e+00],\n",
      "        [-4.6718e+00],\n",
      "        [-7.4783e+00],\n",
      "        [ 1.4148e+00],\n",
      "        [ 1.1277e+01],\n",
      "        [ 1.8204e+00],\n",
      "        [-9.1632e+00],\n",
      "        [-5.7314e+00],\n",
      "        [ 1.3249e-02],\n",
      "        [-1.7939e+00],\n",
      "        [-6.7720e+00],\n",
      "        [ 1.2069e+00],\n",
      "        [ 5.8656e+00],\n",
      "        [-1.6621e+00],\n",
      "        [-6.7015e+00],\n",
      "        [ 1.8101e+01],\n",
      "        [-9.0147e+00],\n",
      "        [ 7.2543e-02],\n",
      "        [-3.5286e+00],\n",
      "        [-5.2031e+00],\n",
      "        [-4.1557e+00],\n",
      "        [ 6.3199e+00],\n",
      "        [ 4.9409e+00],\n",
      "        [-4.7829e+00],\n",
      "        [-9.3742e+00],\n",
      "        [-6.8161e+00],\n",
      "        [ 4.6135e+00],\n",
      "        [-4.5238e+00],\n",
      "        [ 3.6397e+00],\n",
      "        [ 4.6770e+00],\n",
      "        [-2.7589e+00],\n",
      "        [ 3.8513e+00],\n",
      "        [ 1.2931e+01],\n",
      "        [-1.0422e+00],\n",
      "        [ 1.2511e+01],\n",
      "        [ 1.7255e+00],\n",
      "        [ 3.7432e+00],\n",
      "        [ 1.6214e+00],\n",
      "        [ 1.1739e+01],\n",
      "        [-9.6502e-02],\n",
      "        [ 1.9916e+00],\n",
      "        [ 6.0799e-01],\n",
      "        [-3.0146e-01],\n",
      "        [ 2.6104e+00],\n",
      "        [-2.4225e+00],\n",
      "        [-9.5361e+00],\n",
      "        [-5.0121e+00],\n",
      "        [ 7.1835e+00],\n",
      "        [-9.1533e+00],\n",
      "        [-5.2631e+00],\n",
      "        [-6.7841e+00],\n",
      "        [ 5.6248e-01],\n",
      "        [ 2.1539e+00],\n",
      "        [ 9.1711e+00],\n",
      "        [-2.6353e+00],\n",
      "        [-4.1995e+00],\n",
      "        [ 8.9199e-01],\n",
      "        [-4.0025e+00],\n",
      "        [ 4.2696e+00],\n",
      "        [ 4.6543e+00],\n",
      "        [-3.4992e+00],\n",
      "        [ 8.9466e+00],\n",
      "        [-1.8567e+00],\n",
      "        [ 5.6324e+00],\n",
      "        [-1.7084e+00],\n",
      "        [ 2.3360e+00],\n",
      "        [ 6.5827e-01],\n",
      "        [ 1.2271e+01],\n",
      "        [-3.6866e+00],\n",
      "        [-7.2194e+00],\n",
      "        [ 6.3908e+00],\n",
      "        [ 5.3211e+00],\n",
      "        [-3.3142e+00],\n",
      "        [ 4.0678e+00],\n",
      "        [ 5.5511e+00],\n",
      "        [-6.7988e+00],\n",
      "        [ 5.0590e+00],\n",
      "        [-4.6636e+00],\n",
      "        [-2.6391e+00],\n",
      "        [ 1.4190e+00],\n",
      "        [ 6.7776e+00],\n",
      "        [-1.6610e+00],\n",
      "        [ 3.8921e+00],\n",
      "        [-3.4749e+00],\n",
      "        [ 5.3352e+00],\n",
      "        [-4.4057e+00],\n",
      "        [-1.5303e+00],\n",
      "        [ 3.1758e+00],\n",
      "        [-9.3224e+00],\n",
      "        [ 4.2532e+00],\n",
      "        [ 1.8378e+00],\n",
      "        [ 3.0531e+00],\n",
      "        [-3.6527e+00],\n",
      "        [-2.4520e+00],\n",
      "        [ 7.8960e+00],\n",
      "        [ 6.2839e+00],\n",
      "        [ 3.8525e+00],\n",
      "        [-3.5841e+00],\n",
      "        [-4.8563e+00],\n",
      "        [-4.8512e+00],\n",
      "        [-2.1262e+00],\n",
      "        [ 5.1013e+00],\n",
      "        [ 3.2801e-01],\n",
      "        [-4.5866e+00],\n",
      "        [ 1.1195e+00],\n",
      "        [-5.2224e+00],\n",
      "        [ 3.6227e+00],\n",
      "        [ 3.5293e+00],\n",
      "        [-5.8223e+00],\n",
      "        [ 1.7078e+00],\n",
      "        [-3.0417e+00],\n",
      "        [-5.7205e+00],\n",
      "        [-2.5760e+00],\n",
      "        [-3.4505e+00],\n",
      "        [ 5.7404e+00],\n",
      "        [-3.2689e+00],\n",
      "        [-5.9390e+00],\n",
      "        [ 2.4108e+00],\n",
      "        [ 8.8843e+00],\n",
      "        [-1.6373e+00],\n",
      "        [-2.4061e-01],\n",
      "        [ 3.1099e-01],\n",
      "        [ 5.4752e-01],\n",
      "        [ 1.2780e+01],\n",
      "        [ 9.6630e+00],\n",
      "        [-9.9057e+00],\n",
      "        [ 9.7446e-01],\n",
      "        [ 4.7693e+00],\n",
      "        [ 3.1806e+00],\n",
      "        [-4.5110e+00],\n",
      "        [ 6.5726e+00],\n",
      "        [-2.4014e+00],\n",
      "        [ 3.5428e+00],\n",
      "        [-7.1550e+00],\n",
      "        [ 7.9421e+00],\n",
      "        [ 6.7330e+00],\n",
      "        [-4.0243e+00],\n",
      "        [-4.3709e+00],\n",
      "        [ 1.3732e+00],\n",
      "        [ 8.1263e+00],\n",
      "        [-4.3743e+00],\n",
      "        [ 5.1816e+00],\n",
      "        [-2.8138e+00],\n",
      "        [-6.9014e+00],\n",
      "        [ 3.0114e+00],\n",
      "        [-1.0245e+01],\n",
      "        [ 3.2104e+00],\n",
      "        [-9.3431e+00],\n",
      "        [-1.2716e+01],\n",
      "        [-1.7282e+00],\n",
      "        [ 8.7172e+00],\n",
      "        [-4.0059e+00],\n",
      "        [ 1.1317e+00],\n",
      "        [-1.6065e+01],\n",
      "        [ 5.6558e+00],\n",
      "        [ 1.0017e+00],\n",
      "        [ 3.0037e+00],\n",
      "        [-9.7609e-01],\n",
      "        [ 6.6160e+00],\n",
      "        [ 1.8718e+00],\n",
      "        [ 7.2057e+00],\n",
      "        [-6.9621e+00],\n",
      "        [-4.2286e+00],\n",
      "        [ 3.0665e+00],\n",
      "        [-2.4584e+00],\n",
      "        [-2.9106e+00],\n",
      "        [-2.2396e+00],\n",
      "        [-1.6487e+01],\n",
      "        [ 1.9020e+00],\n",
      "        [-5.0461e+00],\n",
      "        [-1.6118e+00],\n",
      "        [ 8.2814e+00],\n",
      "        [-6.4617e+00],\n",
      "        [ 8.4347e+00],\n",
      "        [ 5.0433e+00],\n",
      "        [-4.9103e+00],\n",
      "        [-1.0665e+01],\n",
      "        [ 8.9490e+00],\n",
      "        [-5.5521e+00],\n",
      "        [ 1.5802e+00],\n",
      "        [-4.2044e+00],\n",
      "        [-8.1946e+00],\n",
      "        [-2.0013e+00],\n",
      "        [-2.7921e+00],\n",
      "        [-4.3595e+00],\n",
      "        [-6.2239e+00],\n",
      "        [-1.4246e+00],\n",
      "        [ 1.2461e+01],\n",
      "        [ 2.5097e+00],\n",
      "        [ 3.3941e+00],\n",
      "        [-5.5045e+00],\n",
      "        [-8.1633e+00],\n",
      "        [-4.3482e+00],\n",
      "        [ 5.0998e+00],\n",
      "        [ 7.4147e-01],\n",
      "        [-6.5946e+00],\n",
      "        [-2.9639e+00],\n",
      "        [-5.3183e+00],\n",
      "        [ 6.2251e-01],\n",
      "        [ 8.4350e+00],\n",
      "        [ 1.0958e+01],\n",
      "        [-3.6287e+00],\n",
      "        [ 1.0423e+01],\n",
      "        [-3.2055e+00],\n",
      "        [ 4.6720e+00],\n",
      "        [-4.3286e+00],\n",
      "        [-2.6820e+00],\n",
      "        [-3.2753e+00],\n",
      "        [ 4.0716e+00],\n",
      "        [-7.1850e-01],\n",
      "        [-3.5956e+00],\n",
      "        [-2.7697e+00],\n",
      "        [-6.5882e+00],\n",
      "        [ 7.9177e-01],\n",
      "        [-5.4968e+00],\n",
      "        [-3.6185e+00],\n",
      "        [ 5.0228e+00],\n",
      "        [-1.0787e+00],\n",
      "        [ 1.9069e+00],\n",
      "        [ 3.6495e-01],\n",
      "        [-2.6277e-01],\n",
      "        [-7.5760e+00],\n",
      "        [-7.7336e-02],\n",
      "        [ 1.3256e+01],\n",
      "        [ 1.9563e+00],\n",
      "        [-9.4820e-01],\n",
      "        [-3.3564e+00],\n",
      "        [-9.7526e+00],\n",
      "        [-5.7441e+00],\n",
      "        [ 4.9262e-01],\n",
      "        [-3.7873e+00],\n",
      "        [-2.7617e+00],\n",
      "        [ 1.0484e+00],\n",
      "        [-1.8318e-01],\n",
      "        [-1.7647e+00],\n",
      "        [-3.0814e-01],\n",
      "        [-3.3140e+00],\n",
      "        [-2.3671e-01],\n",
      "        [ 4.5702e-02],\n",
      "        [-8.9020e+00],\n",
      "        [-2.4544e-01],\n",
      "        [ 7.3351e+00],\n",
      "        [-9.2533e+00],\n",
      "        [ 8.3718e-01],\n",
      "        [-1.8080e+01],\n",
      "        [ 4.7409e+00],\n",
      "        [-6.8171e-01],\n",
      "        [-5.8694e+00],\n",
      "        [ 1.8277e-01],\n",
      "        [-9.4661e-02],\n",
      "        [ 7.2349e+00],\n",
      "        [-7.6079e+00],\n",
      "        [-8.2464e+00],\n",
      "        [ 1.8179e+00],\n",
      "        [-4.4898e-01],\n",
      "        [-3.7815e+00],\n",
      "        [ 7.8595e+00],\n",
      "        [-2.1092e+00],\n",
      "        [ 5.5500e+00],\n",
      "        [-4.5337e+00],\n",
      "        [ 4.8602e+00],\n",
      "        [ 5.3111e+00],\n",
      "        [ 1.2015e+01],\n",
      "        [ 3.1407e+00],\n",
      "        [-9.2535e+00],\n",
      "        [ 1.9888e+00],\n",
      "        [ 2.6268e+00],\n",
      "        [ 7.8417e+00],\n",
      "        [ 1.5683e+00],\n",
      "        [-4.3349e+00],\n",
      "        [-8.0206e-01],\n",
      "        [-3.6698e+00],\n",
      "        [ 4.1898e+00],\n",
      "        [ 1.0090e+01],\n",
      "        [ 1.2901e+01],\n",
      "        [-8.3392e+00],\n",
      "        [-7.4602e+00],\n",
      "        [-1.0361e+01],\n",
      "        [ 4.3601e+00],\n",
      "        [ 4.1504e+00],\n",
      "        [ 2.5058e+00],\n",
      "        [-2.3472e+00],\n",
      "        [ 6.1067e+00],\n",
      "        [ 5.4992e+00],\n",
      "        [ 8.0588e+00],\n",
      "        [-2.0064e+00],\n",
      "        [ 2.2089e-02],\n",
      "        [ 4.8678e+00],\n",
      "        [ 7.0129e+00],\n",
      "        [-2.1981e+00],\n",
      "        [-2.5928e+00],\n",
      "        [ 1.5300e+00],\n",
      "        [ 1.1025e-01],\n",
      "        [-3.4990e+00],\n",
      "        [ 4.2560e+00],\n",
      "        [ 3.2857e+00],\n",
      "        [ 1.2182e+01],\n",
      "        [ 9.1909e-01],\n",
      "        [ 3.2229e+00],\n",
      "        [-1.1182e+01],\n",
      "        [ 4.1021e-01],\n",
      "        [-1.1769e+01],\n",
      "        [ 2.5348e+00],\n",
      "        [-8.4357e-01],\n",
      "        [ 5.4534e+00],\n",
      "        [ 7.7627e+00],\n",
      "        [ 1.8222e+00],\n",
      "        [ 5.2599e+00],\n",
      "        [-5.0252e+00],\n",
      "        [ 3.3500e+00],\n",
      "        [ 7.3125e+00],\n",
      "        [ 3.6411e-01],\n",
      "        [-5.0354e+00],\n",
      "        [ 5.5703e-01],\n",
      "        [-2.6342e+00],\n",
      "        [-1.0040e+00],\n",
      "        [-5.2712e+00],\n",
      "        [ 6.8597e+00],\n",
      "        [-1.6458e+00],\n",
      "        [-1.5693e+00],\n",
      "        [-1.1907e-01],\n",
      "        [-7.8669e+00],\n",
      "        [-3.8796e+00],\n",
      "        [-1.3142e+00],\n",
      "        [-4.9887e+00],\n",
      "        [-3.1718e+00],\n",
      "        [-1.0993e+01],\n",
      "        [ 1.9979e+00],\n",
      "        [ 1.7941e+00],\n",
      "        [ 5.8010e+00],\n",
      "        [-7.5434e-01],\n",
      "        [-3.8362e-01],\n",
      "        [ 1.2703e+00],\n",
      "        [-2.0243e+00],\n",
      "        [-2.2497e+00],\n",
      "        [-3.5807e+00],\n",
      "        [ 7.6836e+00],\n",
      "        [ 5.0012e+00],\n",
      "        [ 1.9507e+00],\n",
      "        [-3.2340e-01],\n",
      "        [ 3.9929e+00],\n",
      "        [ 9.1227e-02],\n",
      "        [ 5.5815e+00],\n",
      "        [ 8.8058e+00],\n",
      "        [-4.0224e+00],\n",
      "        [ 2.3759e+00],\n",
      "        [ 2.9554e+00],\n",
      "        [-6.3042e+00],\n",
      "        [-2.0948e+00],\n",
      "        [-2.8408e+00],\n",
      "        [-8.7690e+00],\n",
      "        [-2.9392e+00],\n",
      "        [-1.3548e+00],\n",
      "        [-3.1263e+00],\n",
      "        [ 5.1021e+00],\n",
      "        [ 2.2398e+00],\n",
      "        [-1.0505e+00],\n",
      "        [-5.2575e+00],\n",
      "        [ 1.5826e+00],\n",
      "        [ 4.1375e+00],\n",
      "        [-2.8755e+00],\n",
      "        [-4.1870e+00],\n",
      "        [-2.6255e+00],\n",
      "        [ 3.5790e+00],\n",
      "        [-5.9150e-01],\n",
      "        [ 8.8252e+00],\n",
      "        [-6.8974e+00],\n",
      "        [-6.0000e+00],\n",
      "        [-1.7260e+00],\n",
      "        [ 7.3378e+00],\n",
      "        [-1.9126e+00],\n",
      "        [-1.3094e+01],\n",
      "        [ 2.5539e+00],\n",
      "        [-1.0441e+01],\n",
      "        [ 3.1310e+00],\n",
      "        [ 1.6225e+00],\n",
      "        [-1.0787e+01],\n",
      "        [-8.1000e+00],\n",
      "        [ 4.9029e+00],\n",
      "        [-4.8062e+00],\n",
      "        [ 9.6430e+00],\n",
      "        [ 2.2604e+00],\n",
      "        [ 1.7131e+01],\n",
      "        [-3.0752e-01],\n",
      "        [-5.3903e+00],\n",
      "        [ 3.4648e+00],\n",
      "        [ 1.5012e+01],\n",
      "        [ 1.0452e+01],\n",
      "        [ 4.0665e+00],\n",
      "        [-1.1962e+00],\n",
      "        [ 4.2568e+00],\n",
      "        [ 4.7249e+00],\n",
      "        [ 7.8978e-01],\n",
      "        [-4.8591e+00],\n",
      "        [-3.6292e+00],\n",
      "        [ 2.5468e+00],\n",
      "        [-1.0272e+00],\n",
      "        [ 2.5697e+00],\n",
      "        [ 3.3208e+00],\n",
      "        [ 1.2386e+00],\n",
      "        [ 6.3505e+00],\n",
      "        [ 5.7732e-01],\n",
      "        [-1.3181e+00],\n",
      "        [ 2.6123e+00],\n",
      "        [ 3.1018e+00],\n",
      "        [-1.2956e+01],\n",
      "        [-3.6134e-01],\n",
      "        [-1.7514e+00],\n",
      "        [-3.8145e+00],\n",
      "        [ 7.4292e+00],\n",
      "        [-2.0866e+00],\n",
      "        [ 2.4124e+00],\n",
      "        [-1.0786e+00],\n",
      "        [-2.4256e+00],\n",
      "        [-4.9500e+00],\n",
      "        [-9.4078e+00],\n",
      "        [ 8.1625e+00],\n",
      "        [-3.8751e-01],\n",
      "        [ 1.7073e+01],\n",
      "        [-4.8560e+00],\n",
      "        [ 2.2841e+00],\n",
      "        [-3.4742e+00],\n",
      "        [-2.6287e+00],\n",
      "        [-1.0379e+01],\n",
      "        [-9.9506e+00],\n",
      "        [-4.6626e+00],\n",
      "        [ 6.6956e-02],\n",
      "        [-2.1406e+00],\n",
      "        [-9.2001e+00],\n",
      "        [ 5.8066e+00],\n",
      "        [ 7.6996e+00],\n",
      "        [ 2.9386e+00],\n",
      "        [-3.0319e+00],\n",
      "        [-1.0335e+01],\n",
      "        [-2.8858e+00],\n",
      "        [ 8.3706e+00],\n",
      "        [ 2.0951e-01],\n",
      "        [ 1.0458e+01],\n",
      "        [ 4.0167e-01],\n",
      "        [ 2.1263e+00],\n",
      "        [-2.7335e+00],\n",
      "        [ 5.4653e+00],\n",
      "        [ 1.4237e+00],\n",
      "        [ 8.8442e-01],\n",
      "        [-8.4283e+00],\n",
      "        [-8.7448e+00],\n",
      "        [ 6.4765e-01],\n",
      "        [-3.2236e+00],\n",
      "        [ 5.5365e+00],\n",
      "        [-3.3610e+00],\n",
      "        [ 1.3082e+00],\n",
      "        [-1.2765e+01],\n",
      "        [-4.2484e-02],\n",
      "        [ 4.6403e+00],\n",
      "        [ 7.5280e+00],\n",
      "        [ 7.8930e+00],\n",
      "        [ 8.2893e+00],\n",
      "        [-9.8633e-01],\n",
      "        [-8.6905e+00],\n",
      "        [-1.4831e+00],\n",
      "        [ 2.4490e+00],\n",
      "        [ 9.9195e-01],\n",
      "        [ 9.2379e+00],\n",
      "        [ 2.0834e+00],\n",
      "        [ 8.7423e+00],\n",
      "        [-6.5576e+00],\n",
      "        [ 3.6962e+00],\n",
      "        [ 5.2746e+00],\n",
      "        [-8.2140e+00],\n",
      "        [-6.8782e+00],\n",
      "        [ 1.7237e+00],\n",
      "        [-5.7306e+00],\n",
      "        [-2.4744e+00],\n",
      "        [-1.3565e+00],\n",
      "        [-6.4975e+00],\n",
      "        [ 6.3580e+00],\n",
      "        [-1.2035e+01],\n",
      "        [-1.3142e+01],\n",
      "        [-4.7864e+00],\n",
      "        [-6.5524e+00],\n",
      "        [ 2.3052e+00],\n",
      "        [ 2.4131e+00],\n",
      "        [-1.2214e+00],\n",
      "        [-5.5470e+00],\n",
      "        [ 1.0962e+00],\n",
      "        [ 9.7349e+00],\n",
      "        [ 6.1719e+00],\n",
      "        [-1.8003e+00],\n",
      "        [ 1.1044e+01],\n",
      "        [ 3.5967e+00],\n",
      "        [-3.5381e+00],\n",
      "        [ 2.9616e+00],\n",
      "        [ 4.6443e+00],\n",
      "        [-9.0146e+00],\n",
      "        [-1.4734e+00],\n",
      "        [ 3.6235e+00],\n",
      "        [ 8.4560e+00],\n",
      "        [ 2.8079e+00],\n",
      "        [-5.7352e+00],\n",
      "        [-6.1123e+00],\n",
      "        [ 3.5499e+00],\n",
      "        [-5.6474e-01],\n",
      "        [ 3.1355e+00],\n",
      "        [-5.8580e+00],\n",
      "        [ 6.7614e-01],\n",
      "        [-1.6019e+00],\n",
      "        [-9.8763e+00],\n",
      "        [-3.4251e+00],\n",
      "        [ 1.1459e+01],\n",
      "        [-4.1983e+00],\n",
      "        [-3.3774e-01],\n",
      "        [ 6.8179e-02],\n",
      "        [ 4.2705e+00],\n",
      "        [-3.5338e+00],\n",
      "        [-3.0611e+00],\n",
      "        [-7.7889e+00],\n",
      "        [-1.5484e+00],\n",
      "        [ 5.0319e+00],\n",
      "        [ 9.5721e+00],\n",
      "        [ 4.5536e+00],\n",
      "        [-5.6584e+00],\n",
      "        [-2.6093e+00],\n",
      "        [ 9.5365e+00],\n",
      "        [ 7.1402e+00],\n",
      "        [-1.1902e+00],\n",
      "        [ 4.1630e+00],\n",
      "        [ 7.8800e+00],\n",
      "        [ 1.5722e+00],\n",
      "        [ 7.9872e+00],\n",
      "        [-4.2926e+00],\n",
      "        [-4.1198e+00],\n",
      "        [-4.3795e+00],\n",
      "        [ 8.5693e-01],\n",
      "        [-2.2252e+00],\n",
      "        [ 2.1944e+00],\n",
      "        [ 1.3218e+01],\n",
      "        [-4.0929e-01],\n",
      "        [-3.2652e-01],\n",
      "        [ 3.1775e+00],\n",
      "        [ 6.1496e+00],\n",
      "        [-2.3421e-01],\n",
      "        [-5.0292e+00],\n",
      "        [ 2.3012e+00],\n",
      "        [-1.9055e+00],\n",
      "        [ 3.7306e+00],\n",
      "        [ 2.1888e-01],\n",
      "        [ 3.1082e+00],\n",
      "        [ 5.5897e+00],\n",
      "        [ 3.6588e+00],\n",
      "        [ 5.4883e+00],\n",
      "        [-8.2867e+00],\n",
      "        [ 2.7359e+00],\n",
      "        [ 2.8349e+00],\n",
      "        [ 8.8585e+00],\n",
      "        [-5.6940e+00],\n",
      "        [ 3.4773e+00],\n",
      "        [-1.9663e+00],\n",
      "        [-1.8986e+00],\n",
      "        [-2.9390e+00],\n",
      "        [ 1.1454e+01],\n",
      "        [ 1.6943e+01],\n",
      "        [ 4.7730e+00],\n",
      "        [ 1.4047e+01],\n",
      "        [-6.0458e+00],\n",
      "        [-8.1144e+00],\n",
      "        [ 1.0699e+00],\n",
      "        [ 1.7864e+00],\n",
      "        [-6.0788e+00],\n",
      "        [ 1.8848e-01],\n",
      "        [-7.5589e+00],\n",
      "        [ 2.9496e+00],\n",
      "        [ 9.8798e-02],\n",
      "        [-6.4531e+00],\n",
      "        [-4.9082e+00],\n",
      "        [-3.6701e+00],\n",
      "        [-2.8624e+00],\n",
      "        [ 8.5482e+00],\n",
      "        [-7.1267e+00],\n",
      "        [ 6.0285e+00],\n",
      "        [-6.4173e+00],\n",
      "        [ 3.1180e+00],\n",
      "        [ 9.4381e+00],\n",
      "        [-4.4529e+00],\n",
      "        [ 4.0453e+00],\n",
      "        [ 1.3739e+01],\n",
      "        [-1.0658e+01],\n",
      "        [ 3.3587e+00],\n",
      "        [ 4.1079e+00],\n",
      "        [ 6.8972e+00],\n",
      "        [ 3.4454e+00],\n",
      "        [ 3.9631e+00],\n",
      "        [-5.5679e+00],\n",
      "        [-5.3512e+00],\n",
      "        [ 6.9506e+00],\n",
      "        [-7.4468e+00],\n",
      "        [ 9.3399e+00],\n",
      "        [-1.2485e+01],\n",
      "        [-1.5008e+00],\n",
      "        [ 4.6414e+00],\n",
      "        [ 7.5795e+00],\n",
      "        [-4.2758e+00],\n",
      "        [ 5.7712e+00],\n",
      "        [ 1.8554e+00],\n",
      "        [ 1.0125e+01],\n",
      "        [ 6.8628e+00],\n",
      "        [-3.3951e+00],\n",
      "        [ 1.5278e-01],\n",
      "        [ 5.8836e-01],\n",
      "        [-4.1529e+00],\n",
      "        [-6.9026e+00],\n",
      "        [-4.0011e+00],\n",
      "        [ 5.0314e+00],\n",
      "        [ 3.3454e+00],\n",
      "        [-4.1528e+00],\n",
      "        [ 5.6618e+00],\n",
      "        [ 7.0728e+00],\n",
      "        [-2.7870e+00],\n",
      "        [-4.6021e+00],\n",
      "        [ 8.6285e+00],\n",
      "        [ 2.0935e+00],\n",
      "        [ 2.9539e+00],\n",
      "        [ 4.7863e-01],\n",
      "        [ 8.2881e+00],\n",
      "        [ 1.4012e+00],\n",
      "        [ 4.5612e-01],\n",
      "        [-1.1523e+01],\n",
      "        [ 1.6966e+00],\n",
      "        [ 3.1056e+00],\n",
      "        [-7.8899e+00],\n",
      "        [ 3.9123e+00],\n",
      "        [-2.1790e+00],\n",
      "        [-5.6609e+00],\n",
      "        [-5.2925e+00],\n",
      "        [ 2.3421e+00],\n",
      "        [-1.6830e+00],\n",
      "        [-3.7188e+00],\n",
      "        [-1.9647e-01],\n",
      "        [ 3.7691e+00],\n",
      "        [-3.7607e+00],\n",
      "        [-7.9532e+00],\n",
      "        [-1.1829e+01],\n",
      "        [-2.4846e+00],\n",
      "        [-1.1125e+01],\n",
      "        [-6.2061e+00],\n",
      "        [ 6.4588e+00],\n",
      "        [ 2.8441e+00],\n",
      "        [-4.3803e+00],\n",
      "        [ 8.1520e+00],\n",
      "        [-5.6021e+00],\n",
      "        [ 1.8504e+00],\n",
      "        [-2.8206e+00],\n",
      "        [-1.3786e+00],\n",
      "        [-7.6370e+00],\n",
      "        [ 1.1789e+01],\n",
      "        [-9.5955e+00],\n",
      "        [-1.3658e+00],\n",
      "        [ 2.0381e+00],\n",
      "        [ 1.4366e+00],\n",
      "        [-3.7515e+00],\n",
      "        [-1.2921e+01],\n",
      "        [-9.5637e+00],\n",
      "        [-2.2452e+00],\n",
      "        [ 1.3740e+00],\n",
      "        [-9.8512e+00],\n",
      "        [-5.4382e+00],\n",
      "        [ 7.3959e+00],\n",
      "        [-2.4061e+00],\n",
      "        [-1.1261e+01],\n",
      "        [-6.7273e+00],\n",
      "        [ 2.4095e-01],\n",
      "        [-6.5821e+00],\n",
      "        [-1.7457e-01],\n",
      "        [ 5.7948e+00],\n",
      "        [-1.3521e+00],\n",
      "        [ 5.8704e+00],\n",
      "        [-2.3269e+00],\n",
      "        [ 6.3776e+00],\n",
      "        [-1.2311e+00],\n",
      "        [ 8.4354e+00],\n",
      "        [-1.0481e+00],\n",
      "        [-4.4515e+00],\n",
      "        [ 7.5293e+00],\n",
      "        [ 6.5935e+00],\n",
      "        [-3.5309e+00],\n",
      "        [ 9.0930e+00],\n",
      "        [-7.4199e+00],\n",
      "        [ 1.5421e+00],\n",
      "        [ 7.6818e+00],\n",
      "        [-1.0262e+01],\n",
      "        [-1.0310e+01],\n",
      "        [-2.1714e+00],\n",
      "        [-8.6282e+00],\n",
      "        [-6.2721e+00],\n",
      "        [-9.3179e-01],\n",
      "        [ 3.4593e+00],\n",
      "        [-1.3089e+01],\n",
      "        [-9.5508e-01],\n",
      "        [ 1.2310e+01],\n",
      "        [ 5.2040e-01],\n",
      "        [ 2.2962e+00],\n",
      "        [ 8.2949e+00],\n",
      "        [ 5.0321e+00],\n",
      "        [ 5.6499e+00],\n",
      "        [-1.7121e+00],\n",
      "        [-4.4774e+00],\n",
      "        [-4.9523e+00],\n",
      "        [-2.6493e+00],\n",
      "        [-7.1359e+00],\n",
      "        [-4.4208e+00],\n",
      "        [ 9.6805e+00],\n",
      "        [ 3.5015e+00],\n",
      "        [ 8.7955e+00],\n",
      "        [ 6.8006e+00],\n",
      "        [-4.5469e+00],\n",
      "        [ 4.0222e+00],\n",
      "        [ 2.3230e+00],\n",
      "        [ 5.5362e+00],\n",
      "        [ 2.5966e+00],\n",
      "        [ 1.5477e+00],\n",
      "        [-5.8608e-01],\n",
      "        [ 3.1120e+00]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# GPU implementation\n",
    "def gradient_block_gpu(X, A, H, K, index):\n",
    "\n",
    "        # Select the index-th column of X\n",
    "        X_c = X[:, index:index+1]\n",
    "\n",
    "        # Compute the exponential of A @ X\n",
    "        exp_AX = torch.exp(A @ X)\n",
    "\n",
    "        # Compute the exponential of A @ X for the index-th column\n",
    "        exp_AX_c = torch.exp(A @ X_c)\n",
    "\n",
    "        # Select the index-th column of the one-hot matrix\n",
    "        H_c = H[:, index:index+1]\n",
    "\n",
    "        # Compute the derivative of the loss function with respect to X\n",
    "        df_dX_c = - A.T @ (H_c - (exp_AX_c * (1 / (exp_AX @ K))) )\n",
    "\n",
    "        return df_dX_c\n",
    "    \n",
    "print('Gradient block GPU:', gradient_block_gpu(X_gpu, A_gpu, H_gpu, K_gpu, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(gradient_block_cpu(X_cpu, A_cpu, H_cpu, K_cpu, 0), gradient_block_gpu(X_gpu, A_gpu, H_gpu, K_gpu, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lipschitz function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipschitz constant: 62332.083415006935\n"
     ]
    }
   ],
   "source": [
    "# CPU implementation\n",
    "def Lipschitz_constant_cpu(A):\n",
    "    L = np.linalg.norm(A, 2) * np.linalg.norm(A, 'fro')\n",
    "    return L\n",
    "\n",
    "L_cpu = Lipschitz_constant_cpu(A_cpu)\n",
    "\n",
    "print('Lipschitz constant:', L_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipschitz constant: tensor(62332.0834, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# GPU implementation\n",
    "def Lipschitz_constant_gpu(A):\n",
    "    L = torch.linalg.norm(A, 2) * torch.linalg.norm(A, 'fro')\n",
    "    return L\n",
    "\n",
    "L_gpu = Lipschitz_constant_gpu(A_gpu)\n",
    "\n",
    "print('Lipschitz constant:', L_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU norm2: 62.361347433264555, CPU norm_fro: 999.5307346703992\n",
      "GPU norm2: 62.36134743327395, GPU norm_fro: 999.5307346703992\n"
     ]
    }
   ],
   "source": [
    "norm2_cpu = np.linalg.norm(A_cpu, 2)\n",
    "norm_fro_cpu = np.linalg.norm(A_cpu, 'fro')\n",
    "norm2_gpu = torch.linalg.norm(A_gpu, 2)\n",
    "norm_fro_gpu = torch.linalg.norm(A_gpu, 'fro')\n",
    "print(f'CPU norm2: {norm2_cpu}, CPU norm_fro: {norm_fro_cpu}')\n",
    "print(f'GPU norm2: {norm2_gpu}, GPU norm_fro: {norm_fro_gpu}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(Lipschitz_constant_cpu(A_cpu), Lipschitz_constant_gpu(A_gpu).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "learning_rate = 1 / L_cpu\n",
    "tolerance = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent CPU: [[-0.02805076 -0.02414506 -0.05137511 ...  0.03154081  0.02219599\n",
      "  -0.04019471]\n",
      " [-0.03984501 -0.01307903 -0.05815383 ...  0.02744134  0.01625796\n",
      "  -0.02601091]\n",
      " [-0.04312911  0.04546166  0.00638661 ...  0.06493866  0.02316599\n",
      "   0.0348591 ]\n",
      " ...\n",
      " [-0.03119636  0.01781614 -0.01128832 ... -0.00794128 -0.00343814\n",
      "   0.01383049]\n",
      " [-0.04081123 -0.08230708  0.04398007 ...  0.04145922 -0.06460764\n",
      "   0.01864041]\n",
      " [ 0.00360285 -0.00109459 -0.09453132 ...  0.03095003  0.01533804\n",
      "   0.01482712]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_cpu(X, A, H, K, alpha, num_iterations, epsilon):\n",
    "\n",
    "    # Store the history of the norm, time and update to visualize the convergence\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "\n",
    "    # Compute the gradient of the loss function with respect to X\n",
    "    grad = gradient_cpu(X, A, H, K)\n",
    "\n",
    "    # Initialize the iteration\n",
    "    i = 0\n",
    "\n",
    "    # Loop for a number of iterations\n",
    "    while i < num_iterations and np.linalg.norm(grad) > epsilon:\n",
    "\n",
    "\n",
    "        ## Step 1: start the timer\n",
    "        start = time.time()\n",
    "\n",
    "        ## Step 2: update the parameters\n",
    "        X = X - alpha * grad\n",
    "\n",
    "        ## Step 3: update the gradient of the loss function with respect to the new X\n",
    "        grad = gradient_cpu(X, A, H, K)\n",
    "\n",
    "        ## Step 4: end the timer\n",
    "        end = time.time()\n",
    "\n",
    "        ## Step 5: save the time to the history\n",
    "        time_history.append(end - start)\n",
    "\n",
    "        ## Step 6: save the norm to the history\n",
    "        norm_history.append(np.linalg.norm(grad))\n",
    "\n",
    "        ## Step 7: store the current X\n",
    "        update_history.append(X)\n",
    "\n",
    "        ## Step 8: update the iteration\n",
    "        i += 1\n",
    "\n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "\n",
    "# Run the gradient descent algorithm\n",
    "X_GD_CPU, norm_history_GD_CPU, time_history_GD_CPU, update_history_GD_CPU = gradient_descent_cpu(X_cpu, A_cpu, H_cpu, K_cpu, learning_rate, n_iter, tolerance)\n",
    "\n",
    "print('Gradient descent CPU:', X_GD_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent GPU: tensor([[-0.0281, -0.0241, -0.0514,  ...,  0.0315,  0.0222, -0.0402],\n",
      "        [-0.0398, -0.0131, -0.0582,  ...,  0.0274,  0.0163, -0.0260],\n",
      "        [-0.0431,  0.0455,  0.0064,  ...,  0.0649,  0.0232,  0.0349],\n",
      "        ...,\n",
      "        [-0.0312,  0.0178, -0.0113,  ..., -0.0079, -0.0034,  0.0138],\n",
      "        [-0.0408, -0.0823,  0.0440,  ...,  0.0415, -0.0646,  0.0186],\n",
      "        [ 0.0036, -0.0011, -0.0945,  ...,  0.0310,  0.0153,  0.0148]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_gpu(X, A, H, K, alpha, num_iterations, epsilon):\n",
    "\n",
    "    # Store the history of the norm, time and update to visualize the convergence\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "\n",
    "\n",
    "    # Compute the gradient of the loss function with respect to X\n",
    "    grad = gradient_gpu(X, A, H, K)\n",
    "\n",
    "    # Initialize the iteration\n",
    "    i = 0\n",
    "\n",
    "    # Loop for a number of iterations\n",
    "    while i < num_iterations and torch.linalg.norm(grad) > epsilon:\n",
    "\n",
    "\n",
    "        ## Step 1: start the timer\n",
    "        start = time.time()\n",
    "\n",
    "        ## Step 2: update the parameters\n",
    "        X = X - alpha * grad\n",
    "\n",
    "        ## Step 3: update the gradient of the loss function with respect to the new X\n",
    "        grad = gradient_gpu(X, A, H, K)\n",
    "\n",
    "        ## Step 4: end the timer\n",
    "        end = time.time()\n",
    "\n",
    "        ## Step 5: save the time to the history\n",
    "        time_history.append(end - start)\n",
    "\n",
    "        ## Step 6: save the norm to the history\n",
    "        norm_history.append(torch.linalg.norm(grad))\n",
    "\n",
    "        ## Step 7: store the current X\n",
    "        update_history.append(X)\n",
    "\n",
    "        ## Step 8: update the iteration\n",
    "        i += 1\n",
    "\n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "\n",
    "# Run the gradient descent algorithm\n",
    "X_GD_GPU, norm_history_GD_GPU, time_history_GD_GPU, update_history_GD_GPU = gradient_descent_gpu(X_gpu, A_gpu, H_gpu, K_gpu, learning_rate, n_iter, tolerance)\n",
    "\n",
    "print('Gradient descent GPU:', X_GD_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(X_GD_CPU, X_GD_GPU.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCGD Randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCGD Randomized CPU: [[-0.02553535 -0.03083707 -0.05568235 ...  0.06746253  0.05859978\n",
      "  -0.12933307]\n",
      " [-0.04483715 -0.01185581 -0.06155059 ...  0.0518696   0.05102139\n",
      "  -0.08883798]\n",
      " [-0.04838638  0.04496182  0.00650927 ...  0.14872118  0.02534631\n",
      "   0.11107551]\n",
      " ...\n",
      " [-0.03582165  0.01934532 -0.0091251  ... -0.035255    0.02030053\n",
      "   0.04875944]\n",
      " [-0.04314158 -0.09215194  0.04314617 ...  0.07066738 -0.07572039\n",
      "   0.04346636]\n",
      " [ 0.00319407  0.0021725  -0.10499875 ...  0.03610681  0.01665754\n",
      "  -0.01314275]]\n"
     ]
    }
   ],
   "source": [
    "def BCDG_randomized_cpu(X, A, H, K, alpha, num_iterations, epsilon, j):\n",
    "\n",
    "    # Store the history of the norm, time and cost to visualize the convergence\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "\n",
    "    # Compute the gradient of the loss function with respect to X\n",
    "    grad = gradient_cpu(X, A, H, K)\n",
    "\n",
    "    # Initialize the iteration\n",
    "    i = 0\n",
    "\n",
    "    # Loop for a number of iterations\n",
    "    while i < num_iterations and np.linalg.norm(grad) > epsilon:\n",
    "\n",
    "        ## Step 1: start the timer\n",
    "        start = time.time()\n",
    "\n",
    "        ## Step 2: randomly select a block\n",
    "        rand_index = np.random.randint(0, j)          # randomly select a block\n",
    "\n",
    "\n",
    "        ## Step 4: compute the gradient of the block\n",
    "        random_gradient_block_new = gradient_block_cpu(X, A, H, K, rand_index)\n",
    "\n",
    "        ## Step 5: update the block\n",
    "        grad[:, rand_index:rand_index+1] = random_gradient_block_new\n",
    "\n",
    "        ## Step 6: update the parameters\n",
    "        X = X - alpha * grad\n",
    "\n",
    "        ## Step 7: end the timer\n",
    "        end = time.time()\n",
    "\n",
    "        ## Step 8: save the time to the history\n",
    "        time_history.append(end - start)\n",
    "\n",
    "        ## Step 9: save the norm to the history\n",
    "        norm_history.append(np.linalg.norm(grad))\n",
    "\n",
    "        ## Step 10: store the current X\n",
    "        update_history.append(X)\n",
    "\n",
    "        ## Step 11: update the iteration\n",
    "        i += 1\n",
    "\n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "# Run the BCDG algorithm\n",
    "X_BCGD_R_CPU, norm_history_BCGD_R_CPU, time_history_BCGD_R_CPU, update_history_BCGD_R_CPU = BCDG_randomized_cpu(X_cpu, A_cpu, H_cpu, K_cpu, learning_rate, n_iter, tolerance, 10)\n",
    "\n",
    "print('BCGD Randomized CPU:', X_BCGD_R_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCGD Randomized GPU: tensor([[-0.0255, -0.0307, -0.0557,  ...,  0.0675,  0.0586, -0.1293],\n",
      "        [-0.0448, -0.0118, -0.0616,  ...,  0.0519,  0.0510, -0.0888],\n",
      "        [-0.0484,  0.0448,  0.0065,  ...,  0.1487,  0.0253,  0.1111],\n",
      "        ...,\n",
      "        [-0.0358,  0.0194, -0.0091,  ..., -0.0353,  0.0203,  0.0488],\n",
      "        [-0.0432, -0.0921,  0.0431,  ...,  0.0707, -0.0757,  0.0435],\n",
      "        [ 0.0032,  0.0021, -0.1050,  ...,  0.0361,  0.0167, -0.0131]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def BCDG_randomized_gpu(X, A, H, K, alpha, num_iterations, epsilon, j):\n",
    "    # Store histories\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "    \n",
    "    # Compute initial gradient\n",
    "    grad = gradient_gpu(X, A, H, K)\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_iterations and torch.norm(grad) > epsilon:\n",
    "        start = time.time()\n",
    "        \n",
    "        # Random block selection\n",
    "        rand_index = torch.randint(0, j, (1,)).item()\n",
    "        \n",
    "        # Update gradient block\n",
    "        random_gradient_block = gradient_block_gpu(X, A, H, K, rand_index)\n",
    "        grad[:, rand_index:rand_index+1] = random_gradient_block\n",
    "        \n",
    "        # Update parameters\n",
    "        X = X - alpha * grad\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # Store history\n",
    "        time_history.append(end - start)\n",
    "        norm_history.append(torch.norm(grad).item())\n",
    "        update_history.append(X.clone())\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "# Run algorithm\n",
    "X_BCGD_R_GPU, norm_history_BCGD_R_GPU, time_history_BCGD_R_GPU, update_history_BCGD_R_GPU = BCDG_randomized_gpu(X_gpu, A_gpu, H_gpu, K_gpu, learning_rate, n_iter, tolerance, 10)\n",
    "\n",
    "print('BCGD Randomized GPU:', X_BCGD_R_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert np.allclose(X_BCGD_R_CPU, X_BCGD_R_GPU.cpu().numpy())\n",
    "# The above assertion is not working because the BCDG algorithm is randomized and the random block selection is different in the CPU and GPU implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BCDG with Gauss-Southwell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCGD Gauss-Southwell CPU: [[-0.02764379 -0.02399116 -0.05192358 ...  0.03281978  0.02296528\n",
      "  -0.04168276]\n",
      " [-0.04062594 -0.01288317 -0.05930996 ...  0.02845722  0.01745391\n",
      "  -0.02716354]\n",
      " [-0.0436753   0.04392772  0.00686085 ...  0.06854954  0.0236048\n",
      "   0.03780965]\n",
      " ...\n",
      " [-0.03149526  0.01824567 -0.01159977 ... -0.00903711 -0.00287712\n",
      "   0.01473154]\n",
      " [-0.04083438 -0.08451908  0.04423799 ...  0.04286417 -0.06387197\n",
      "   0.01937369]\n",
      " [ 0.00261229 -0.0017357  -0.09576838 ...  0.03042003  0.01528254\n",
      "   0.01447632]]\n"
     ]
    }
   ],
   "source": [
    "def BCDG_GS_cpu(X, A, H, K, alpha, num_iterations, epsilon, j):\n",
    "\n",
    "    # Store the history of the norm, time and cost to visualize the convergence\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "\n",
    "    # Compute the gradient of the loss function with respect to X\n",
    "    grad = gradient_cpu(X, A, H, K)\n",
    "\n",
    "    # Compute the norm of the columns of the gradient\n",
    "    norm_grad_column = np.linalg.norm(grad, axis=0)\n",
    "\n",
    "    # Initialize the iteration\n",
    "    iteration = 0\n",
    "\n",
    "    # Loop for a number of iterations\n",
    "    while iteration < num_iterations and np.linalg.norm(grad) > epsilon:\n",
    "\n",
    "        ## Step 1: start the timer\n",
    "        start = time.time()\n",
    "\n",
    "        ## Step 2: select a block using the Gauss-Southwell rule\n",
    "        gs_index = np.argmax(norm_grad_column)\n",
    "\n",
    "        ## Step 3: compute the gradient of the block\n",
    "        gs_gradient_block_new = gradient_block_cpu(X, A, H, K, gs_index)\n",
    "\n",
    "        ## Step 4: compute the norm of the gradient of the block\n",
    "        norm_grad_column[gs_index] = np.linalg.norm(gs_gradient_block_new)\n",
    "\n",
    "        ## Step 5: update the block\n",
    "        grad[:, gs_index:gs_index+1] = gs_gradient_block_new\n",
    "\n",
    "        ## Step 6: update the parameters\n",
    "        X = X - alpha * grad\n",
    "\n",
    "        ## Step 7: end the timer\n",
    "        end = time.time()\n",
    "\n",
    "        ## Step 8: save the time to the history\n",
    "        time_history.append(end - start)\n",
    "\n",
    "        ## Step 9: save the norm to the history\n",
    "        norm_history.append(np.linalg.norm(grad))\n",
    "\n",
    "        ## Step 10: store the current X\n",
    "        update_history.append(X)\n",
    "\n",
    "        ## Step 11: increment the iteration\n",
    "        iteration += 1\n",
    "\n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "# Run the BCDG algorithm\n",
    "X_BCGD_GS_CPU, norm_history_BCGD_GS_CPU, time_history_BCGD_GS_CPU, update_history_BCGD_GS_CPU = BCDG_GS_cpu(X_cpu, A_cpu, H_cpu, K_cpu, learning_rate, n_iter, tolerance, 10)\n",
    "print('BCGD Gauss-Southwell CPU:', X_BCGD_GS_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCGD Gauss-Southwell GPU: tensor([[-0.0276, -0.0240, -0.0519,  ...,  0.0328,  0.0230, -0.0417],\n",
      "        [-0.0406, -0.0129, -0.0593,  ...,  0.0285,  0.0175, -0.0272],\n",
      "        [-0.0437,  0.0439,  0.0069,  ...,  0.0685,  0.0236,  0.0378],\n",
      "        ...,\n",
      "        [-0.0315,  0.0182, -0.0116,  ..., -0.0090, -0.0029,  0.0147],\n",
      "        [-0.0408, -0.0845,  0.0442,  ...,  0.0429, -0.0639,  0.0194],\n",
      "        [ 0.0026, -0.0017, -0.0958,  ...,  0.0304,  0.0153,  0.0145]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def BCDG_GS_gpu(X, A, H, K, alpha, num_iterations, epsilon, j):\n",
    "    # Store histories\n",
    "    norm_history = []\n",
    "    time_history = []\n",
    "    update_history = []\n",
    "    \n",
    "    \n",
    "    # Initial gradient computation\n",
    "    grad = gradient_gpu(X, A, H, K)\n",
    "    norm_grad_column = torch.norm(grad, dim=0)\n",
    "    \n",
    "    iteration = 0\n",
    "    while iteration < num_iterations and torch.norm(grad) > epsilon:\n",
    "        start = time.time()\n",
    "        \n",
    "        # Gauss-Southwell block selection\n",
    "        gs_index = torch.argmax(norm_grad_column).item()\n",
    "        \n",
    "        # Update gradient block\n",
    "        gs_gradient_block_new = gradient_block_gpu(X, A, H, K, gs_index)\n",
    "        norm_grad_column[gs_index] = torch.norm(gs_gradient_block_new)\n",
    "        grad[:, gs_index:gs_index+1] = gs_gradient_block_new\n",
    "        \n",
    "        # Update parameters\n",
    "        X = X - alpha * grad\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # Store history\n",
    "        time_history.append(end - start)\n",
    "        norm_history.append(torch.norm(grad).item())\n",
    "        update_history.append(X.clone())\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "    return X, norm_history, time_history, update_history\n",
    "\n",
    "# Run algorithm\n",
    "X_BCGD_GS_GPU, norm_history_BCGD_GS_GPU, time_history_BCGD_GS_GPU, update_history_BCGD_GS_GPU = BCDG_GS_gpu(X_gpu, A_gpu, H_gpu, K_gpu, learning_rate, n_iter, tolerance, 10)\n",
    "\n",
    "print('BCGD Gauss-Southwell GPU:', X_BCGD_GS_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(X_BCGD_GS_CPU, X_BCGD_GS_GPU.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
